{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nipype.interfaces.io import DataSink, SelectFiles, DataGrabber \n",
    "from nipype.interfaces.utility import IdentityInterface, Function    \n",
    "from nipype.pipeline.engine import Node, Workflow, JoinNode, MapNode\n",
    "import nipype.interfaces.mrtrix3 as mtx\n",
    "import nipype.interfaces.mrtrix.convert as mtxc\n",
    "import nipype.interfaces.mrtrix.preprocess as mtxp\n",
    "import nipype.interfaces.fsl as fsl\n",
    "from pandas import Series, read_csv, to_numeric\n",
    "from glob import glob\n",
    "from os.path import abspath, expanduser, join\n",
    "from os import chdir, remove, getcwd, makedirs\n",
    "from shutil import copyfile\n",
    "from nipype import config, logging\n",
    "from datetime import date\n",
    "today = str(date.today())\n",
    "config.enable_debug_mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resources for MRTRIX:\n",
    "# https://community.mrtrix.org/t/the-output-of-tck2connectome/345/25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set user and path variables\n",
    "local='False'\n",
    "user = expanduser('~')\n",
    "if user == '/Users/lucindasisk':\n",
    "    if local == 'True':\n",
    "        laptop = '/Users/lucindasisk/Desktop/DATA'\n",
    "        home = join(user, 'Desktop/Milgram/candlab')\n",
    "        raw_dir = join(home, 'data/mri/bids_recon/shapes')\n",
    "        proc_dir = join(home, 'analyses/shapes/dwi')\n",
    "        workflow_dir = join(laptop, 'workflows_ls')\n",
    "        data_dir = join(laptop, 'data_ls')\n",
    "    else:\n",
    "        home = join(user, 'Desktop/Milgram/candlab')\n",
    "        raw_dir = join(home, 'data/mri/bids_recon/shapes')\n",
    "        proc_dir = join(home, 'analyses/shapes/dwi/data')\n",
    "        workflow_dir = join(home, 'analyses/shapes/dwi/workflows')\n",
    "        data_dir = join(home, 'analyses/shapes/dwi/data')\n",
    "else:\n",
    "    home = '/gpfs/milgram/project/gee_dylan/candlab'\n",
    "    raw_dir = join(home, 'data/mri/bids_recon/shapes')\n",
    "    proc_dir = join(home, 'analyses/shapes/dwi/data')\n",
    "    workflow_dir = join(home, 'analyses/shapes/dwi/workflows')\n",
    "    data_dir = join(home, 'analyses/shapes/dwi/data')\n",
    "    \n",
    "# Read in subject subject_list\n",
    "subject_info = read_csv(\n",
    "    home + '/scripts/shapes/mri/dwi/shapes_dwi_subjList_08.07.2019.txt', sep=' ', header=None)\n",
    "subject_list = subject_info[0].tolist()\n",
    "\n",
    "# Manual subject list\n",
    "# subject_list = ['sub-A208', 'sub-A207']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup Datasink, Infosource, Selectfiles\n",
    "\n",
    "datasink = Node(DataSink(base_directory = data_dir,\n",
    "                        substitutions = [('_subject_id_', '')]),\n",
    "                   name='datasink')\n",
    "\n",
    "#Set infosource iterables\n",
    "infosource = Node(IdentityInterface(fields=['subject_id']),\n",
    "                  name=\"infosource\")\n",
    "infosource.iterables = [('subject_id', subject_list)]\n",
    "\n",
    "#SelectFiles\n",
    "template = dict(dti = join(proc_dir,'3_Eddy_Corrected/{subject_id}/eddy_corrected_resample.nii.gz'),\n",
    "                bval = join(raw_dir, '{subject_id}/ses-shapesV1/dwi/{subject_id}_ses-shapesV1_dwi.bval'),\n",
    "                bvec = join(proc_dir,'3_Eddy_Corrected/{subject_id}/eddy_corrected.eddy_rotated_bvecs'),\n",
    "                t1 = join(proc_dir, '2_Preprocessed/{subject_id}/{subject_id}_ses-shapesV1_T1w_flirt_brain.nii.gz'),\n",
    "                mni=join(home, 'atlases/MNI152_T1_2mm_brain.nii.gz')\n",
    "               )\n",
    "\n",
    "sf = Node(SelectFiles(template, \n",
    "                      base_directory = home),\n",
    "          name = 'sf')\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nodes for Diffusion workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate binary mask\n",
    "bet=Node(fsl.BET(frac=0.2,\n",
    "                mask=True),\n",
    "        name='bet')\n",
    "\n",
    "#Convert bvals and bvecs to fslgrad\n",
    "gradconv = Node(mtx.MRConvert(),\n",
    "               name = 'gradconv')\n",
    "\n",
    "#Generate 5 tissue type (5tt) segmentation using FAST algorithm\n",
    "seg5tt = Node(mtx.Generate5tt(algorithm = 'fsl',\n",
    "                             out_file = 'T1s_5tt_segmented.nii.gz'),\n",
    "             name='seg5tt')\n",
    "\n",
    "#Estimate response functions for spherical deconvolution using the specified algorithm (Dhollander)\n",
    "#https://nipype.readthedocs.io/en/latest/interfaces/generated/interfaces.mrtrix3/preprocess.html#responsesd\n",
    "#https://mrtrix.readthedocs.io/en/latest/constrained_spherical_deconvolution/response_function_estimation.html#response-function-estimation\n",
    "#Max_sh (lmax variable) determined in shell order from here: https://mrtrix.readthedocs.io/en/3.0_rc2/constrained_spherical_deconvolution/lmax.html\n",
    "#DWI has 5 shells: 7 b0 volumes, 6 b500 vols, 15 b1000 vols, 15 b2000 bols, 60 b3000 vols\n",
    "dwiresp = Node(mtx.ResponseSD(algorithm = 'dhollander',\n",
    "                              max_sh=[0,2,4,4,8],\n",
    "                              wm_file = 'wm_response.txt',\n",
    "                              gm_file = 'gm_response.txt',\n",
    "                              csf_file = 'csf_response.txt'),\n",
    "              name='dwiresp')\n",
    "\n",
    "#Estimate fiber orientation distributions from diffusion data sing spherical deconvolution\n",
    "#https://nipype.readthedocs.io/en/latest/interfaces/generated/interfaces.mrtrix3/reconst.html\n",
    "#https://mrtrix.readthedocs.io/en/latest/constrained_spherical_deconvolution/multi_shell_multi_tissue_csd.html\n",
    "#Max SH here determined by tissue type - chose 8,8,8 per forum recommendations\n",
    "mscsd = Node(mtx.EstimateFOD(algorithm = 'msmt_csd',\n",
    "                             bval_scale = 'yes',\n",
    "                            max_sh = [8,8,8]),\n",
    "            name='mscsd')\n",
    "\n",
    "#Perform Tractography - iFOD2 (https://nipype.readthedocs.io/en/latest/interfaces/generated/interfaces.mrtrix3/tracking.html) \n",
    "tract = Node(mtx.Tractography(algorithm='iFOD2',\n",
    "                              select=100000, #Jiook has done 100 million streamlines\n",
    "                              n_trials=10000, \n",
    "                              out_file='msCSD_brain_tracktography.tck'),\n",
    "            name='tract')\n",
    "\n",
    "#Perform probabilistic tractography (Tensor_Prob)\n",
    "tract_prob = Node(mtx.Tractography(algorithm='Tensor_Prob',\n",
    "                              select=100000, #Jiook has done 100 million streamlines\n",
    "                              n_trials=10000, \n",
    "                              out_file='tensorProb_brain_tracktography.tck'),\n",
    "                  name='tract_prob')\n",
    "\n",
    "#Convert whole-brain tractography from MrTrix format to TrackVis\n",
    "trkconvert = Node(mtxc.MRTrix2TrackVis(out_filename = 'msCSD_tractography_converted.trk'),\n",
    "                 name='trkconvert')\n",
    "\n",
    "trkconvert2 = Node(mtxc.MRTrix2TrackVis(out_filename = 'tensorProb_tractography_converted.trk'),\n",
    "                 name='trkconvert2')\n",
    "\n",
    "#convert eddy-corrected raw DTI to tensor format\n",
    "dwi2tensor = Node(mtx.FitTensor(out_file = 'whole_brain_tensorfile.mif',\n",
    "                               bval_scale='yes'),\n",
    "                name='dwi2tensor')\n",
    "\n",
    "#Compute FA from tensor files\n",
    "tensor2fa = Node(mtx.TensorMetrics(out_fa='whole_brain_FA.mif'),\n",
    "                name='tensor2fa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_flow = Workflow(name = 'tensor_flow')\n",
    "tensor_flow.connect([(infosource, sf, [('subject_id','subject_id')]),\n",
    "                     (sf, bet, [('t1', 'in_file')]),\n",
    "                     (sf, dwi2tensor, [('dwi', 'in_file')]),\n",
    "                     (dwi2tensor, datasink, [('out_file', '6_Tensor_Data')]),\n",
    "                     (dwi2tensor, tensor2fa, [('out_file', 'in_file')]),\n",
    "                     (tensor2fa, datasink, [('FA', '6_Tensor_Data.@par')])\n",
    "                    ])\n",
    "tensor_flow.base_dir = workflow_dir\n",
    "tensor_flow.write_graph(graph2use = 'flat')\n",
    "dwi = tensor_flow.run('MultiProc', plugin_args={'n_procs': 4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tract_flow = Workflow(name = 'tract_flow')\n",
    "tract_flow.connect([(infosource, sf, [('subject_id','subject_id')]),\n",
    "                    #Skullstrip T1\n",
    "                    (sf, bet, [('t1', 'in_file')]),\n",
    "                    #Segment T1 image with FSL 5tt algorithm\n",
    "                    (sf, seg5tt, [('t1', 'in_file')]),\n",
    "                    (seg5tt, datasink, [('out_file', '5_Tract_Reconstruction')]),\n",
    "                    #Convert bval/bvec to gradient tables\n",
    "                    (sf, gradconv, [('dti', 'in_file'),\n",
    "                                   ('bval','in_bval'),\n",
    "                                   ('bvec', 'in_bvec')]),\n",
    "                    #Compute FOD response functions\n",
    "                    (gradconv, dwiresp, [('out_file', 'in_file')]),\n",
    "                    (dwiresp, datasink, [('wm_file', '5_Tract_Reconstruction.@par'),\n",
    "                                        ('gm_file', '5_Tract_Reconstruction.@par.@par'),\n",
    "                                        ('csf_file', '5_Tract_Reconstruction.@par.@par.@par')]),\n",
    "                    (gradconv, mscsd, [('out_file', 'in_file')]),\n",
    "                    #Perform multi-shell constrained spherical deconvolution\n",
    "                    (dwiresp, mscsd, [('wm_file', 'wm_txt'),\n",
    "                                      ('gm_file', 'gm_txt'),\n",
    "                                      ('csf_file', 'csf_txt')]),\n",
    "                    (mscsd, tract, [('wm_odf', 'in_file')]),\n",
    "                    (mscsd, datasink, [('wm_odf', '5_Tract_Reconstruction.@par.@par.@par.@par'),\n",
    "                                       ('gm_odf', '5_Tract_Reconstruction.@par.@par.@par.@par.@par'),\n",
    "                                       ('csf_odf','5_Tract_Reconstruction.@par.@par.@par.@par.@par.@par')]),\n",
    "                    (sf, tract, [('bval', 'in_bval'),\n",
    "                                 ('bvec', 'in_bvec')]),\n",
    "                    (bet, tract, [('mask_file', 'seed_image')]),\n",
    "                    #Convert ms-csd files to global tractography\n",
    "                    (tract, trkconvert, [('out_file', 'in_file')]),\n",
    "                    (sf, trkconvert, [('t1','image_file')]),\n",
    "                    (sf, trkconvert, [('t1','registration_image_file')]),\n",
    "                    (trkconvert, datasink, [('out_file', '5_Tract_Reconstruction.@par.@par.@par.@par.@par.@par.@par')]),\n",
    "                    (tract, datasink, [('out_file', '5_Tract_Reconstruction.@par.@par.@par.@par.@par.@par.@par.@par')]),      \n",
    "                    (bet, datasink, [('mask_file','5_Tract_Reconstruction.@par.@par.@par.@par.@par.@par.@par.@par.@par')]),\n",
    "                    (bet, datasink, [('out_file','5_Tract_Reconstruction.@par.@par.@par.@par.@par.@par.@par.@par.@par.@par.@par.@par')]),\n",
    "                    (gradconv, tract_prob, [('out_file', 'in_file')]),\n",
    "                    (bet, tract_prob, [('mask_file', 'seed_image')]),\n",
    "                    (tract_prob, datasink, [('out_file','5_Tract_Reconstruction.@par.@par.@par.@par.@par.@par.@par.@par.@par.@par')]),   \n",
    "                    (tract_prob, trkconvert2, [('out_file', 'in_file')]),\n",
    "                    (sf, trkconvert2, [('t1','image_file')]),\n",
    "                    (sf, trkconvert2, [('t1','registration_image_file')]),\n",
    "                    (trkconvert2, datasink, [('out_file', '5_Tract_Reconstruction.@par.@par.@par.@par.@par.@par.@par.@par.@par.@par.@par')]),   \n",
    "                    #Nodes to create tensor FA files\n",
    "                    (gradconv, dwi2tensor, [('out_file', 'in_file')]),\n",
    "                    (dwi2tensor, datasink, [('out_file', '6_Tensor_Data')]),\n",
    "                    (dwi2tensor, tensor2fa, [('out_file', 'in_file')]),\n",
    "                    (tensor2fa, datasink, [('out_fa', '6_Tensor_Data.@par')]),\n",
    "                   ])\n",
    "tract_flow.base_dir = workflow_dir\n",
    "tract_flow.write_graph(graph2use = 'flat')\n",
    "dwi = tract_flow.run('MultiProc', plugin_args={'n_procs': 4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
