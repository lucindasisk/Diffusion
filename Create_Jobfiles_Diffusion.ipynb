{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dsQ job submission array\n",
    "#### Commands: \n",
    "\n",
    "\n",
    "ml load dSQ/1.05\n",
    "\n",
    "1: dsq --job-file 1_preproc_dsq_job_array.txt --mem-per-cpu 50g -t 6:00:00 --mail-type ALL --partition gpu --cpus-per-task=1 --gres=gpu:2\n",
    "\n",
    "2: dsq --job-file 2_csd_dsq_job_array.txt --mem-per-cpu 10g -t 50:00:00 --mail-type ALL --partition verylong\n",
    "\n",
    "\n",
    "4: dsq --job-file 4_fixel_job_array.txt --mem-per-cpu 10g -t 10:00:00 --mail-type ALL --partition verylong\n",
    "\n",
    "\n",
    "5: dsq --job-file 5_tract_dsq_job_array.txt --mem-per-cpu 50g -t 20:00:00 --mail-type ALL --partition verylong\n",
    "\n",
    "7: dsq --job-file 7_fixelAnalysis_dsq_job_array.txt --mem-per-cpu 10g -t 2:00:00 --mail-type ALL --partition verylong\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "home = '/home/lms233/Github/Diffusion'\n",
    "candpath = '/gpfs/milgram/pi/gee_dylan/candlab'\n",
    "data = candpath + '/analyses/shapes/dwi/data'\n",
    "dwi = candpath + '/analyses/shapes/dwi'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_info = pd.Series(glob(data + '/1_Preprocessed_Data/sub*'))\n",
    "subs = subject_info.replace(data + '/1_Preprocessed_Data/', '')\n",
    "all_subjects = subs.tolist()\n",
    "merge_sublist = pd.DataFrame(subs, columns = ['Subject'])\n",
    "merge_sublist['Subject'] = merge_sublist['Subject'].str.replace('sub-', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106 subs had DTI and RI data, and motion under threshold\n"
     ]
    }
   ],
   "source": [
    "#Subjects with RI and DTI data under motion threshold\n",
    "ri_sublist = pd.read_csv(dwi + '/subjectlist_preDiss_motion0.75_n107_2021-03-29.csv', names = ['index', 'Subject'], header = 0)\n",
    "print('{} subs had DTI and RI data, and motion under threshold'.format(len(ri_sublist)))\n",
    "risubs = 'sub-' + ri_sublist['Subject']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sub-A217', 'sub-A218', 'sub-A222', 'sub-A223', 'sub-A225', 'sub-A228', 'sub-A229', 'sub-A230', 'sub-A231', 'sub-A232', 'sub-A233', 'sub-A234', 'sub-A236', 'sub-A237', 'sub-A238', 'sub-A240', 'sub-A242', 'sub-A246', 'sub-A248', 'sub-A250', 'sub-A251', 'sub-A253', 'sub-A255', 'sub-A256', 'sub-A257', 'sub-A258', 'sub-A260', 'sub-A262', 'sub-A266', 'sub-A268', 'sub-A271', 'sub-A272', 'sub-A276', 'sub-A279', 'sub-A280', 'sub-A281', 'sub-A283', 'sub-A285', 'sub-A286', 'sub-A288', 'sub-A291', 'sub-A293', 'sub-A294', 'sub-A548', 'sub-A553', 'sub-A554', 'sub-A555', 'sub-A556', 'sub-A557', 'sub-A592', 'sub-A593', 'sub-A609', 'sub-A611', 'sub-A619', 'sub-A620', 'sub-A621', 'sub-A622', 'sub-A637', 'sub-A643', 'sub-A646', 'sub-A650', 'sub-A651', 'sub-A653', 'sub-A656', 'sub-A660', 'sub-A661', 'sub-A663', 'sub-A664', 'sub-A665', 'sub-A666', 'sub-A680', 'sub-A682', 'sub-A686', 'sub-A687', 'sub-A688', 'sub-A689', 'sub-A692', 'sub-A694', 'sub-A695', 'sub-A696', 'sub-A698', 'sub-A704', 'sub-A707', 'sub-A708', 'sub-A715', 'sub-A717', 'sub-A718', 'sub-A720', 'sub-A721', 'sub-A723', 'sub-A724', 'sub-A726', 'sub-A729', 'sub-A733', 'sub-A738', 'sub-A739', 'sub-A742', 'sub-A743', 'sub-A744', 'sub-A746', 'sub-A749', 'sub-A992', 'sub-A993', 'sub-A994', 'sub-A995', 'sub-A996']\n"
     ]
    }
   ],
   "source": [
    "print(risubs.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/milgram/project/gee_dylan/lms233/conda_envs/mybrainiak/lib/python3.7/site-packages/ipykernel_launcher.py:5: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "#Generate subs who didn't process fully (MSMT CSD)\n",
    "subjslist = []\n",
    "for i in range(0, len(all_subjects)):\n",
    "    sub = all_subjects[i]\n",
    "    newlist = pd.Series(glob(data+ '/4_Deconvolution/*'))\n",
    "    newsubs = newlist.replace(data + '/4_Deconvolution/', '').tolist()\n",
    "    if sub in newsubs:\n",
    "        pass\n",
    "    else:\n",
    "        subjslist.append(sub)\n",
    "\n",
    "notrun_subjects = list(set(subjslist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Generate subs who didn't process fully (Tractography)\n",
    "# notrun_tractsubs = []\n",
    "# for i in range(0, len(ri_sublist)):\n",
    "#     sub = 'sub-' + ri_sublist['Subject'].tolist()[i]\n",
    "#     newlist = pd.Series(glob(data + '/tract_output/*/*.csv'))\n",
    "#     for j in range(0, len(newlist)):\n",
    "#         newsub = newlist[j].replace(data + '/tract_output/', '')\n",
    "#         newsub2 = newsub.split('/')[0]\n",
    "#         newlist.append(stnewsub2))\n",
    "#     if sub in newsublist:\n",
    "#         pass\n",
    "#     else:\n",
    "#         notrun_tractsubs.append(sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106\n",
      "106\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "print(len(subs))\n",
    "print(len(notrun_subjects))\n",
    "print(len(notrun_tractsubs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create batch file for preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set subjects\n",
    "subjects = risubs\n",
    "commands_preproc = []\n",
    "\n",
    "for i in range(0, len(subjects)):\n",
    "    sub = subjects[i]\n",
    "    commands_preproc.append('sh 1_sbatch_preproc.sh {}'.format(sub))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = pd.DataFrame(commands_preproc)\n",
    "out.to_csv(home + '/1_preproc_dsq_job_array.txt', sep = '\\t', header = False, index=False, \n",
    "           quoting=csv.QUOTE_NONE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create batch file for MS CSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set subjects\n",
    "subjects = risubs\n",
    "\n",
    "commands_csd = []\n",
    "\n",
    "for i in range(0, len(subjects)):\n",
    "    sub = subjects[i]\n",
    "    commands_csd.append('sh 2_sbatch_csd.sh {}'.format(sub))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = pd.DataFrame(commands_csd)\n",
    "out.to_csv(home + '/2_csd_dsq_job_array.txt', sep = '\\t', header = False, index=False, \n",
    "           quoting=csv.QUOTE_NONE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create batch file for fixel registration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set subjects\n",
    "subjects = ri_sublist['Subject'].tolist()\n",
    "\n",
    "commands_fixel = []\n",
    "\n",
    "for i in range(0, len(subjects)):\n",
    "    sub = subjects[i]\n",
    "    commands_fixel.append('sh 4_sbatch_register_FOD.sh sub-{}'.format(sub))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117\n"
     ]
    }
   ],
   "source": [
    "out = pd.DataFrame(commands_fixel)\n",
    "print(len(out))\n",
    "out.to_csv(home + '/4_fixel_job_array.txt', sep = '\\t', header = False, index=False, \n",
    "           quoting=csv.QUOTE_NONE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create batch file for final fixel extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = ri_sublist['Subject'].tolist()\n",
    "commands_fixan = []\n",
    "\n",
    "for i in range(0, len(subjects)):\n",
    "    sub = subjects[i]\n",
    "    commands_fixan.append('sh 7_sbatch_TransformSubjectFODtoTemplate.sh sub-{}'.format(sub))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_tract = pd.DataFrame(commands_fixan)\n",
    "out_tract.to_csv(home + '/7_fixelAnalysis_dsq_job_array.txt', sep = '\\t', header = False, index=False, \n",
    "           quoting=csv.QUOTE_NONE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create batch file for TractSeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = risubs\n",
    "commands_tract = []\n",
    "\n",
    "for i in range(0, len(subjects)):\n",
    "    sub = subjects[i]\n",
    "    commands_tract.append('sh 5_TractSegFlow.sh {}'.format(sub))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_tract = pd.DataFrame(commands_tract)\n",
    "out_tract.to_csv(home + '/5_tract_dsq_job_array.txt', sep = '\\t', header = False, index=False, \n",
    "           quoting=csv.QUOTE_NONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
