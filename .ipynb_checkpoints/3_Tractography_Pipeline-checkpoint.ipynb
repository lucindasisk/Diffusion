{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nipype.interfaces.io import DataSink, SelectFiles, DataGrabber \n",
    "from nipype.interfaces.utility import IdentityInterface, Function    \n",
    "from nipype.pipeline.engine import Node, Workflow, JoinNode, MapNode\n",
    "import nipype.interfaces.mrtrix3 as mtx\n",
    "import nipype.interfaces.mrtrix.convert as mtxc\n",
    "import nipype.interfaces.mrtrix.preprocess as mtxp\n",
    "import nipype.interfaces.fsl as fsl\n",
    "from pandas import Series, read_csv, to_numeric\n",
    "from glob import glob\n",
    "from os.path import abspath, expanduser, join\n",
    "from os import chdir, remove, getcwd, makedirs\n",
    "from shutil import copyfile\n",
    "from nipype import config, logging\n",
    "from datetime import date\n",
    "today = str(date.today())\n",
    "config.enable_debug_mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resources for MRTRIX:\n",
    "# https://community.mrtrix.org/t/the-output-of-tck2connectome/345/25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set user and path variables\n",
    "local='False'\n",
    "user = expanduser('~')\n",
    "if user == '/Users/lucindasisk':\n",
    "    if local == 'True':\n",
    "        laptop = '/Users/lucindasisk/Desktop/DATA'\n",
    "        home = join(user, 'Desktop/Milgram/candlab')\n",
    "        raw_dir = join(home, 'data/mri/bids_recon/shapes')\n",
    "        proc_dir = join(home, 'analyses/shapes/dwi')\n",
    "        workflow_dir = join(laptop, 'workflows_ls')\n",
    "        data_dir = join(laptop, 'data_ls')\n",
    "    else:\n",
    "        home = join(user, 'Desktop/Milgram/candlab')\n",
    "        raw_dir = join(home, 'data/mri/bids_recon/shapes')\n",
    "        proc_dir = join(home, 'analyses/shapes/dwi/data')\n",
    "        workflow_dir = join(home, 'analyses/shapes/dwi/workflows')\n",
    "        data_dir = join(home, 'analyses/shapes/dwi/data')\n",
    "else:\n",
    "    home = '/gpfs/milgram/project/gee_dylan/candlab'\n",
    "    raw_dir = join(home, 'data/mri/bids_recon/shapes')\n",
    "    proc_dir = join(home, 'analyses/shapes/dwi/data')\n",
    "    workflow_dir = join(home, 'analyses/shapes/dwi/workflows')\n",
    "    data_dir = join(home, 'analyses/shapes/dwi/data')\n",
    "    \n",
    "# Read in subject subject_list\n",
    "subject_info = read_csv(\n",
    "    home + '/scripts/shapes/mri/dwi/shapes_dwi_subjList_08.07.2019.txt', sep=' ', header=None)\n",
    "# subject_list = subject_info[0].tolist()\n",
    "\n",
    "# Manual subject list\n",
    "subject_list = ['sub-A200']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup Datasink, Infosource, Selectfiles\n",
    "\n",
    "datasink = Node(DataSink(base_directory = data_dir,\n",
    "                        substitutions = [('_subject_id_', '')]),\n",
    "                   name='datasink')\n",
    "\n",
    "#Set infosource iterables\n",
    "infosource = Node(IdentityInterface(fields=['subject_id']),\n",
    "                  name=\"infosource\")\n",
    "infosource.iterables = [('subject_id', subject_list)]\n",
    "\n",
    "#SelectFiles\n",
    "template = dict(dti = join(proc_dir,'3_Eddy_Corrected/{subject_id}/eddy_corrected.nii.gz'),\n",
    "                bval = join(raw_dir, '{subject_id}/ses-shapesV1/dwi/{subject_id}_ses-shapesV1_dwi.bval'),\n",
    "                bvec = join(proc_dir,'3_Eddy_Corrected/{subject_id}/eddy_corrected.eddy_rotated_bvecs'),\n",
    "                t1 = join(proc_dir, '1_Check_Unwarped/{subject_id}/{subject_id}_ses-shapesV1_T1w_flirt_brain.nii.gz'),\n",
    "                mni=join(home, 'atlases/MNI152_T1_2mm_brain.nii.gz')\n",
    "               )\n",
    "\n",
    "sf = Node(SelectFiles(template, \n",
    "                      base_directory = home),\n",
    "          name = 'sf')\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nodes for Diffusion workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Generate binary mask\n",
    "# bet=Node(fsl.BET(frac=0.2,\n",
    "#                 mask=True),\n",
    "#         name='bet')\n",
    "\n",
    "#Convert bvals and bvecs to fslgrad\n",
    "gradconv = Node(mtx.MRConvert(),\n",
    "               name = 'gradconv')\n",
    "\n",
    "#Generate 5 tissue type (5tt) segmentation using FAST algorithm\n",
    "seg5tt = Node(mtx.Generate5tt(algorithm = 'fsl',\n",
    "                             out_file = 'T1s_5tt_segmented.nii.gz'),\n",
    "             name='seg5tt')\n",
    "\n",
    "#Estimate response functions for spherical deconvolution using the specified algorithm (Dhollander)\n",
    "#https://nipype.readthedocs.io/en/latest/interfaces/generated/interfaces.mrtrix3/preprocess.html#responsesd\n",
    "#https://mrtrix.readthedocs.io/en/latest/constrained_spherical_deconvolution/response_function_estimation.html#response-function-estimation\n",
    "#Max_sh (lmax variable) determined in shell order from here: https://mrtrix.readthedocs.io/en/3.0_rc2/constrained_spherical_deconvolution/lmax.html\n",
    "#DWI has 5 shells: 7 b0 volumes, 6 b500 vols, 15 b1000 vols, 15 b2000 bols, 60 b3000 vols\n",
    "dwiresp = Node(mtx.ResponseSD(algorithm = 'dhollander',\n",
    "                              max_sh=[0,2,4,4,8],\n",
    "                              wm_file = 'wm_response.txt',\n",
    "                              gm_file = 'gm_response.txt',\n",
    "                              csf_file = 'csf_response.txt'),\n",
    "              name='dwiresp')\n",
    "\n",
    "#Estimate fiber orientation distributions from diffusion data sing spherical deconvolution\n",
    "#https://nipype.readthedocs.io/en/latest/interfaces/generated/interfaces.mrtrix3/reconst.html\n",
    "#https://mrtrix.readthedocs.io/en/latest/constrained_spherical_deconvolution/multi_shell_multi_tissue_csd.html\n",
    "#Max SH here determined by tissue type - chose 8,8,8 per forum recommendations\n",
    "mscsd = Node(mtx.EstimateFOD(algorithm = 'msmt_csd',\n",
    "                             bval_scale = 'yes',\n",
    "                            max_sh = [8,8,8]),\n",
    "            name='mscsd')\n",
    "\n",
    "#Perform Tractography - iFOD2 (https://nipype.readthedocs.io/en/latest/interfaces/generated/interfaces.mrtrix3/tracking.html) \n",
    "tract = Node(mtx.Tractography(algorithm='iFOD2',\n",
    "                              select=100000, #Jiook has done 100 million streamlines\n",
    "                              n_trials=10000, \n",
    "                              out_file='msCSD_brain_tracktography.tck'),\n",
    "            name='tract')\n",
    "\n",
    "# #Perform probabilistic tractography (Tensor_Prob)\n",
    "# tract_prob = Node(mtx.Tractography(algorithm='Tensor_Prob',\n",
    "#                               select=100000, #Jiook has done 100 million streamlines\n",
    "#                               n_trials=10000, \n",
    "#                               out_file='tensorProb_brain_tracktography.tck'),\n",
    "#                   name='tract_prob')\n",
    "\n",
    "# #Convert whole-brain tractography from MrTrix format to TrackVis\n",
    "# trkconvert = Node(mtxc.MRTrix2TrackVis(out_filename = 'msCSD_tractography_converted.trk'),\n",
    "#                  name='trkconvert')\n",
    "\n",
    "# trkconvert2 = Node(mtxc.MRTrix2TrackVis(out_filename = 'tensorProb_tractography_converted.trk'),\n",
    "#                  name='trkconvert2')\n",
    "\n",
    "# #convert eddy-corrected raw DTI to tensor format\n",
    "# dwi2tensor = Node(mtx.FitTensor(out_file = 'whole_brain_tensorfile.mif',\n",
    "#                                bval_scale='yes'),\n",
    "#                 name='dwi2tensor')\n",
    "\n",
    "# #Compute FA from tensor files\n",
    "# tensor2fa = Node(mtx.TensorMetrics(out_fa='whole_brain_FA.mif'),\n",
    "#                 name='tensor2fa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210310-19:49:04,853 nipype.workflow DEBUG:\n",
      "\t (tensor_flow.infosource, tensor_flow.sf): No edge data\n",
      "210310-19:49:04,854 nipype.workflow DEBUG:\n",
      "\t (tensor_flow.infosource, tensor_flow.sf): new edge data: {'connect': [('subject_id', 'subject_id')]}\n",
      "210310-19:49:04,855 nipype.workflow DEBUG:\n",
      "\t (tensor_flow.sf, tract_flow.seg5tt): No edge data\n",
      "210310-19:49:04,856 nipype.workflow DEBUG:\n",
      "\t (tensor_flow.sf, tract_flow.seg5tt): new edge data: {'connect': [('t1', 'in_file')]}\n",
      "210310-19:49:04,857 nipype.workflow DEBUG:\n",
      "\t (tract_flow.seg5tt, tensor_flow.datasink): No edge data\n",
      "210310-19:49:04,857 nipype.workflow DEBUG:\n",
      "\t (tract_flow.seg5tt, tensor_flow.datasink): new edge data: {'connect': [('out_file', '5_Tract_Reconstruction')]}\n",
      "210310-19:49:04,858 nipype.workflow DEBUG:\n",
      "\t (tensor_flow.sf, tract_flow.gradconv): No edge data\n",
      "210310-19:49:04,859 nipype.workflow DEBUG:\n",
      "\t (tensor_flow.sf, tract_flow.gradconv): new edge data: {'connect': [('dti', 'in_file'), ('bval', 'in_bval'), ('bvec', 'in_bvec')]}\n",
      "210310-19:49:04,859 nipype.workflow DEBUG:\n",
      "\t (tract_flow.gradconv, tract_flow.dwiresp): No edge data\n",
      "210310-19:49:04,860 nipype.workflow DEBUG:\n",
      "\t (tract_flow.gradconv, tract_flow.dwiresp): new edge data: {'connect': [('out_file', 'in_file')]}\n",
      "210310-19:49:04,861 nipype.workflow DEBUG:\n",
      "\t (tract_flow.dwiresp, tensor_flow.datasink): No edge data\n",
      "210310-19:49:04,861 nipype.workflow DEBUG:\n",
      "\t (tract_flow.dwiresp, tensor_flow.datasink): new edge data: {'connect': [('wm_file', '5_Tract_Reconstruction.@par'), ('gm_file', '5_Tract_Reconstruction.@par.@par'), ('csf_file', '5_Tract_Reconstruction.@par.@par.@par')]}\n",
      "210310-19:49:04,862 nipype.workflow DEBUG:\n",
      "\t (tract_flow.gradconv, tract_flow.mscsd): No edge data\n",
      "210310-19:49:04,863 nipype.workflow DEBUG:\n",
      "\t (tract_flow.gradconv, tract_flow.mscsd): new edge data: {'connect': [('out_file', 'in_file')]}\n",
      "210310-19:49:04,865 nipype.workflow DEBUG:\n",
      "\t (tract_flow.dwiresp, tract_flow.mscsd): No edge data\n",
      "210310-19:49:04,865 nipype.workflow DEBUG:\n",
      "\t (tract_flow.dwiresp, tract_flow.mscsd): new edge data: {'connect': [('wm_file', 'wm_txt'), ('gm_file', 'gm_txt'), ('csf_file', 'csf_txt')]}\n",
      "210310-19:49:04,866 nipype.workflow DEBUG:\n",
      "\t (tract_flow.mscsd, tract_flow.tract): No edge data\n",
      "210310-19:49:04,867 nipype.workflow DEBUG:\n",
      "\t (tract_flow.mscsd, tract_flow.tract): new edge data: {'connect': [('wm_odf', 'in_file')]}\n",
      "210310-19:49:04,868 nipype.workflow DEBUG:\n",
      "\t (tract_flow.mscsd, tensor_flow.datasink): No edge data\n",
      "210310-19:49:04,868 nipype.workflow DEBUG:\n",
      "\t (tract_flow.mscsd, tensor_flow.datasink): new edge data: {'connect': [('wm_odf', '5_Tract_Reconstruction.@par.@par.@par.@par'), ('gm_odf', '5_Tract_Reconstruction.@par.@par.@par.@par.@par'), ('csf_odf', '5_Tract_Reconstruction.@par.@par.@par.@par.@par.@par')]}\n",
      "210310-19:49:05,367 nipype.workflow DEBUG:\n",
      "\t Creating flat graph for workflow: tract_flow\n",
      "210310-19:49:05,479 nipype.workflow DEBUG:\n",
      "\t expanding workflow: tract_flow\n",
      "210310-19:49:05,480 nipype.workflow DEBUG:\n",
      "\t processing node: tensor_flow.infosource\n",
      "210310-19:49:05,481 nipype.workflow DEBUG:\n",
      "\t processing node: tensor_flow.sf\n",
      "210310-19:49:05,481 nipype.workflow DEBUG:\n",
      "\t processing node: tract_flow.gradconv\n",
      "210310-19:49:05,482 nipype.workflow DEBUG:\n",
      "\t processing node: tract_flow.dwiresp\n",
      "210310-19:49:05,482 nipype.workflow DEBUG:\n",
      "\t processing node: tract_flow.mscsd\n",
      "210310-19:49:05,483 nipype.workflow DEBUG:\n",
      "\t processing node: tract_flow.tract\n",
      "210310-19:49:05,484 nipype.workflow DEBUG:\n",
      "\t processing node: tract_flow.seg5tt\n",
      "210310-19:49:05,484 nipype.workflow DEBUG:\n",
      "\t processing node: tensor_flow.datasink\n",
      "210310-19:49:05,485 nipype.workflow DEBUG:\n",
      "\t finished expanding workflow: tract_flow\n",
      "210310-19:49:05,489 nipype.workflow DEBUG:\n",
      "\t using input graph\n",
      "210310-19:49:08,28 nipype.workflow DEBUG:\n",
      "\t creating dot graph\n",
      "210310-19:49:10,57 nipype.workflow INFO:\n",
      "\t Generated workflow graph: /Users/lucindasisk/Desktop/Milgram/candlab/analyses/shapes/dwi/workflows/tract_flow/graph.png (graph2use=flat, simple_form=True).\n",
      "210310-19:49:10,67 nipype.workflow DEBUG:\n",
      "\t [MultiProc] Starting (n_procs=4, mem_gb=28.80, cwd=/Users/lucindasisk/Dropbox/Github/Diffusion)\n",
      "210310-19:49:10,70 nipype.workflow DEBUG:\n",
      "\t Creating flat graph for workflow: tract_flow\n",
      "210310-19:49:10,76 nipype.workflow DEBUG:\n",
      "\t expanding workflow: tract_flow\n",
      "210310-19:49:10,77 nipype.workflow DEBUG:\n",
      "\t processing node: tensor_flow.infosource\n",
      "210310-19:49:10,77 nipype.workflow DEBUG:\n",
      "\t processing node: tensor_flow.sf\n",
      "210310-19:49:10,78 nipype.workflow DEBUG:\n",
      "\t processing node: tract_flow.gradconv\n",
      "210310-19:49:10,78 nipype.workflow DEBUG:\n",
      "\t processing node: tract_flow.dwiresp\n",
      "210310-19:49:10,79 nipype.workflow DEBUG:\n",
      "\t processing node: tract_flow.mscsd\n",
      "210310-19:49:10,80 nipype.workflow DEBUG:\n",
      "\t processing node: tract_flow.tract\n",
      "210310-19:49:10,81 nipype.workflow DEBUG:\n",
      "\t processing node: tract_flow.seg5tt\n",
      "210310-19:49:10,81 nipype.workflow DEBUG:\n",
      "\t processing node: tensor_flow.datasink\n",
      "210310-19:49:10,82 nipype.workflow DEBUG:\n",
      "\t finished expanding workflow: tract_flow\n",
      "210310-19:49:10,83 nipype.workflow INFO:\n",
      "\t Workflow tract_flow settings: ['check', 'execution', 'logging', 'monitoring']\n",
      "210310-19:49:10,86 nipype.workflow DEBUG:\n",
      "\t PE: expanding iterables\n",
      "210310-19:49:10,87 nipype.workflow DEBUG:\n",
      "\t Detected iterable nodes [tensor_flow.infosource]\n",
      "210310-19:49:10,88 nipype.workflow DEBUG:\n",
      "\t Expanding the iterable node tensor_flow.infosource...\n",
      "210310-19:49:10,89 nipype.workflow DEBUG:\n",
      "\t node: tensor_flow.infosource iterables: {'subject_id': <function _standardize_iterables.<locals>.make_field_func.<locals>.<lambda> at 0x7fcff8a588c0>}\n",
      "210310-19:49:10,89 nipype.workflow DEBUG:\n",
      "\t ('subnodes:', [tensor_flow.infosource, tensor_flow.sf, tract_flow.seg5tt, tensor_flow.datasink, tract_flow.gradconv, tract_flow.dwiresp, tract_flow.mscsd, tract_flow.tract])\n",
      "210310-19:49:10,94 nipype.workflow DEBUG:\n",
      "\t [Node] infosource - setting input subject_id = sub-A200\n",
      "210310-19:49:10,95 nipype.workflow DEBUG:\n",
      "\t Parameterization: paramstr=_subject_id_sub-A200\n",
      "210310-19:49:10,95 nipype.workflow DEBUG:\n",
      "\t PE: expanding iterables ... done\n",
      "210310-19:49:10,96 nipype.workflow DEBUG:\n",
      "\t [Node] sf - setting input subject_id = sub-A200\n",
      "210310-19:49:10,97 nipype.workflow DEBUG:\n",
      "\t Removed the identity node tensor_flow.infosource from the graph.\n",
      "210310-19:49:13,367 nipype.workflow DEBUG:\n",
      "\t Performing depth first search\n",
      "210310-19:49:14,886 nipype.workflow INFO:\n",
      "\t Running in parallel.\n",
      "210310-19:49:14,889 nipype.workflow DEBUG:\n",
      "\t Progress: 7 jobs, 0/0/1 (done/running/ready), 0/7 (pending_tasks/waiting).\n",
      "210310-19:49:14,890 nipype.workflow DEBUG:\n",
      "\t Tasks currently running: 0. Pending: 0.\n",
      "210310-19:49:14,891 nipype.workflow INFO:\n",
      "\t [MultiProc] Running 0 tasks, and 1 jobs ready. Free memory (GB): 28.80/28.80, Free processors: 4/4.\n",
      "210310-19:49:14,943 nipype.workflow DEBUG:\n",
      "\t Allocating tensor_flow.sf ID=0 (0.20GB, 1 threads). Free: 28.60GB, 3 threads.\n",
      "210310-19:49:15,341 nipype.workflow DEBUG:\n",
      "\t [Node] Hashes: [('base_directory', '/Users/lucindasisk/Desktop/Milgram/candlab'), ('force_lists', False), ('raise_on_empty', True), ('sort_filelist', True), ('subject_id', 'sub-A200')], b55969a6e4f3187f1953032d2972e1b0, /Users/lucindasisk/Desktop/Milgram/candlab/analyses/shapes/dwi/workflows/tensor_flow/_subject_id_sub-A200/sf/_0xb55969a6e4f3187f1953032d2972e1b0.json, ['/Users/lucindasisk/Desktop/Milgram/candlab/analyses/shapes/dwi/workflows/tensor_flow/_subject_id_sub-A200/sf/_0xb55969a6e4f3187f1953032d2972e1b0.json']\n",
      "210310-19:49:15,342 nipype.workflow DEBUG:\n",
      "\t [Node] Up-to-date cache found for \"tensor_flow.sf\".\n",
      "210310-19:49:15,343 nipype.workflow DEBUG:\n",
      "\t Checking hash \"tensor_flow.sf\" locally: cached=True, updated=True.\n",
      "210310-19:49:15,362 nipype.workflow DEBUG:\n",
      "\t [MultiProc] Submitted task tensor_flow.sf (taskid=1).\n",
      "210310-19:49:15,367 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"tensor_flow.sf\" in \"/Users/lucindasisk/Desktop/Milgram/candlab/analyses/shapes/dwi/workflows/tensor_flow/_subject_id_sub-A200/sf\".\n",
      "210310-19:49:15,469 nipype.workflow DEBUG:\n",
      "\t [Node] Hashes: [('base_directory', '/Users/lucindasisk/Desktop/Milgram/candlab'), ('force_lists', False), ('raise_on_empty', True), ('sort_filelist', True), ('subject_id', 'sub-A200')], b55969a6e4f3187f1953032d2972e1b0, /Users/lucindasisk/Desktop/Milgram/candlab/analyses/shapes/dwi/workflows/tensor_flow/_subject_id_sub-A200/sf/_0xb55969a6e4f3187f1953032d2972e1b0.json, ['/Users/lucindasisk/Desktop/Milgram/candlab/analyses/shapes/dwi/workflows/tensor_flow/_subject_id_sub-A200/sf/_0xb55969a6e4f3187f1953032d2972e1b0.json']\n",
      "210310-19:49:15,473 nipype.workflow DEBUG:\n",
      "\t [Node] Up-to-date cache found for \"tensor_flow.sf\".\n",
      "210310-19:49:15,475 nipype.workflow DEBUG:\n",
      "\t [Node] Rerunning cached, up-to-date node \"tensor_flow.sf\"\n",
      "210310-19:49:15,759 nipype.utils DEBUG:\n",
      "\t Removing contents of /Users/lucindasisk/Desktop/Milgram/candlab/analyses/shapes/dwi/workflows/tensor_flow/_subject_id_sub-A200/sf\n",
      "210310-19:49:16,893 nipype.workflow DEBUG:\n",
      "\t Progress: 7 jobs, 0/1/0 (done/running/ready), 1/6 (pending_tasks/waiting).\n",
      "210310-19:49:16,894 nipype.workflow DEBUG:\n",
      "\t Tasks currently running: 1. Pending: 1.\n",
      "210310-19:49:16,896 nipype.workflow INFO:\n",
      "\t [MultiProc] Running 1 tasks, and 0 jobs ready. Free memory (GB): 28.60/28.80, Free processors: 3/4.\n",
      "                     Currently running:\n",
      "                       * tensor_flow.sf\n",
      "210310-19:49:21,506 nipype.workflow DEBUG:\n",
      "\t [Node] Writing pre-exec report to \"/Users/lucindasisk/Desktop/Milgram/candlab/analyses/shapes/dwi/workflows/tensor_flow/_subject_id_sub-A200/sf/_report/report.rst\"\n",
      "210310-19:49:24,732 nipype.workflow INFO:\n",
      "\t [Node] Running \"sf\" (\"nipype.interfaces.io.SelectFiles\")\n",
      "210310-19:49:26,455 nipype.workflow DEBUG:\n",
      "\t Needed files: /Users/lucindasisk/Desktop/Milgram/candlab/analyses/shapes/dwi/data/3_Eddy_Corrected/sub-A200/eddy_corrected.nii.gz;/Users/lucindasisk/Desktop/Milgram/candlab/data/mri/bids_recon/shapes/sub-A200/ses-shapesV1/dwi/sub-A200_ses-shapesV1_dwi.bval;/Users/lucindasisk/Desktop/Milgram/candlab/analyses/shapes/dwi/data/3_Eddy_Corrected/sub-A200/eddy_corrected.eddy_rotated_bvecs;/Users/lucindasisk/Desktop/Milgram/candlab/analyses/shapes/dwi/data/1_Check_Unwarped/sub-A200/sub-A200_ses-shapesV1_T1w_flirt_brain.nii.gz;/Users/lucindasisk/Desktop/Milgram/candlab/atlases/MNI152_T1_2mm_brain.nii.gz;/Users/lucindasisk/Desktop/Milgram/candlab/analyses/shapes/dwi/workflows/tensor_flow/_subject_id_sub-A200/sf/_0xb55969a6e4f3187f1953032d2972e1b0_unfinished.json;/Users/lucindasisk/Desktop/Milgram/candlab/analyses/shapes/dwi/workflows/tensor_flow/_subject_id_sub-A200/sf/_inputs.pklz;/Users/lucindasisk/Desktop/Milgram/candlab/analyses/shapes/dwi/workflows/tensor_flow/_subject_id_sub-A200/sf/_node.pklz\n",
      "210310-19:49:26,458 nipype.workflow DEBUG:\n",
      "\t Needed dirs: /Users/lucindasisk/Desktop/Milgram/candlab/analyses/shapes/dwi/workflows/tensor_flow/_subject_id_sub-A200/sf/_report\n",
      "210310-19:49:26,460 nipype.workflow DEBUG:\n",
      "\t Removing files: \n",
      "210310-19:49:26,463 nipype.workflow DEBUG:\n",
      "\t Saving results file: '/Users/lucindasisk/Desktop/Milgram/candlab/analyses/shapes/dwi/workflows/tensor_flow/_subject_id_sub-A200/sf/result_sf.pklz'\n"
     ]
    }
   ],
   "source": [
    "tract_flow = Workflow(name = 'tract_flow')\n",
    "tract_flow.connect([(infosource, sf, [('subject_id','subject_id')]),\n",
    "                    #Segment T1 image with FSL 5tt algorithm\n",
    "                    (sf, seg5tt, [('t1', 'in_file')]),\n",
    "                    (seg5tt, datasink, [('out_file', '5_Tract_Reconstruction')]),\n",
    "                    #Convert bval/bvec to gradient tables\n",
    "                    (sf, gradconv, [('dti', 'in_file'),\n",
    "                                   ('bval','in_bval'),\n",
    "                                   ('bvec', 'in_bvec')]),\n",
    "                    #Compute FOD response functions\n",
    "                    (gradconv, dwiresp, [('out_file', 'in_file')]),\n",
    "                    (dwiresp, datasink, [('wm_file', '5_Tract_Reconstruction.@par'),\n",
    "                                        ('gm_file', '5_Tract_Reconstruction.@par.@par'),\n",
    "                                        ('csf_file', '5_Tract_Reconstruction.@par.@par.@par')]),\n",
    "                    (gradconv, mscsd, [('out_file', 'in_file')]),\n",
    "                    #Perform multi-shell constrained spherical deconvolution\n",
    "                    (dwiresp, mscsd, [('wm_file', 'wm_txt'),\n",
    "                                      ('gm_file', 'gm_txt'),\n",
    "                                      ('csf_file', 'csf_txt')]),\n",
    "                    (mscsd, tract, [('wm_odf', 'in_file')]),\n",
    "                    (mscsd, datasink, [('wm_odf', '5_Tract_Reconstruction.@par.@par.@par.@par'),\n",
    "                                       ('gm_odf', '5_Tract_Reconstruction.@par.@par.@par.@par.@par'),\n",
    "                                       ('csf_odf','5_Tract_Reconstruction.@par.@par.@par.@par.@par.@par')])\n",
    "#                     (sf, tract, [('bval', 'in_bval'),\n",
    "#                                  ('bvec', 'in_bvec')]),\n",
    "#                     (bet, tract, [('mask_file', 'seed_image')]),\n",
    "#                     #Convert ms-csd files to global tractography\n",
    "#                     (tract, trkconvert, [('out_file', 'in_file')]),\n",
    "#                     (sf, trkconvert, [('t1','image_file')]),\n",
    "#                     (sf, trkconvert, [('t1','registration_image_file')]),\n",
    "#                     (trkconvert, datasink, [('out_file', '5_Tract_Reconstruction.@par.@par.@par.@par.@par.@par.@par')]),\n",
    "#                     (tract, datasink, [('out_file', '5_Tract_Reconstruction.@par.@par.@par.@par.@par.@par.@par.@par')]),      \n",
    "#                     (bet, datasink, [('mask_file','5_Tract_Reconstruction.@par.@par.@par.@par.@par.@par.@par.@par.@par')]),\n",
    "#                     (bet, datasink, [('out_file','5_Tract_Reconstruction.@par.@par.@par.@par.@par.@par.@par.@par.@par.@par.@par.@par')]),\n",
    "#                     (gradconv, tract_prob, [('out_file', 'in_file')]),\n",
    "#                     (bet, tract_prob, [('mask_file', 'seed_image')]),\n",
    "#                     (tract_prob, datasink, [('out_file','5_Tract_Reconstruction.@par.@par.@par.@par.@par.@par.@par.@par.@par.@par')]),   \n",
    "#                     (tract_prob, trkconvert2, [('out_file', 'in_file')]),\n",
    "#                     (sf, trkconvert2, [('t1','image_file')]),\n",
    "#                     (sf, trkconvert2, [('t1','registration_image_file')]),\n",
    "#                     (trkconvert2, datasink, [('out_file', '5_Tract_Reconstruction.@par.@par.@par.@par.@par.@par.@par.@par.@par.@par.@par')]),   \n",
    "#                     #Nodes to create tensor FA files\n",
    "#                     (gradconv, dwi2tensor, [('out_file', 'in_file')]),\n",
    "#                     (dwi2tensor, datasink, [('out_file', '6_Tensor_Data')]),\n",
    "#                     (dwi2tensor, tensor2fa, [('out_file', 'in_file')]),\n",
    "#                     (tensor2fa, datasink, [('out_fa', '6_Tensor_Data.@par')]),\n",
    "                   ])\n",
    "tract_flow.base_dir = workflow_dir\n",
    "tract_flow.write_graph(graph2use = 'flat')\n",
    "dwi = tract_flow.run('MultiProc', plugin_args={'n_procs': 4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
