{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nipype.interfaces.io import DataSink, SelectFiles, DataGrabber \n",
    "from nipype.interfaces.utility import IdentityInterface, Function    \n",
    "from nipype.pipeline.engine import Node, Workflow, JoinNode, MapNode\n",
    "from nipype.interfaces import fsl\n",
    "from nipype.interfaces import freesurfer as fsr\n",
    "import nipype.interfaces.mrtrix3 as mtx\n",
    "from pandas import Series, read_csv, to_numeric\n",
    "from glob import glob\n",
    "from os.path import abspath, expanduser, join\n",
    "from os import chdir, remove, getcwd, makedirs\n",
    "from shutil import copyfile\n",
    "from nipype import config, logging\n",
    "from datetime import date\n",
    "import AFQ\n",
    "today = str(date.today())\n",
    "config.enable_debug_mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set variables\n",
    "subject_list = ['sub-A200']#, 'sub-A201']\n",
    "\n",
    "user = expanduser('~')\n",
    "\n",
    "home = join(user,'Box/LS_Folders/CANDLab_LS/DATA')\n",
    "workflow_dir = join(user, 'Desktop/workflow_LS2')\n",
    "data_dir = join(user, 'Desktop/DataDir_LS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create preprocessing Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup Datasink, Infosource, Selectfiles\n",
    "\n",
    "datasink = Node(DataSink(base_directory = data_dir,\n",
    "                        substitutions = [('_subject_id_', '')]),\n",
    "                   name='datasink')\n",
    "\n",
    "#Set infosource iterables\n",
    "infosource = Node(IdentityInterface(fields=['subject_id']),\n",
    "                  name=\"infosource\")\n",
    "infosource.iterables = [('subject_id', subject_list)]\n",
    "\n",
    "#SelectFiles\n",
    "template = dict(t1 = join(home,'{subject_id}/anat/{subject_id}_ses-shapesV1_T1w.nii.gz'),\n",
    "                dti = join(home,'{subject_id}/dwi/{subject_id}_ses-shapesV1_dwi.nii.gz'),\n",
    "                bval = join(home,'{subject_id}/dwi/{subject_id}_ses-shapesV1_dwi.bval'),\n",
    "                bvec = join(home,'{subject_id}/dwi/{subject_id}_ses-shapesV1_dwi.bvec'),\n",
    "                fmappa = join(home,'{subject_id}/fmap/{subject_id}_ses-shapesV1_acq-dwi_dir-PA_epi.nii.gz'),  \n",
    "                fmapap = join(home,'{subject_id}/fmap/{subject_id}_ses-shapesV1_acq-dwi_dir-AP_epi.nii.gz'),\n",
    "                aps = join(home, 'shapes_acqparams.txt'),\n",
    "                index = join(home, 'shapes_index.txt')\n",
    "               )#,\n",
    "               # index = join(home, 'index.txt'),\n",
    "               # aps = join(home, 'acqparams.txt'),\n",
    "               # tryxfm = join(home, 'transform.txt'))\n",
    "\n",
    "sf = Node(SelectFiles(template, \n",
    "                      base_directory = home),\n",
    "          name = 'sf')\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge AP/PA encoding direction fieldmaps\n",
    "def create_merged_files(ap, pa):\n",
    "    from nipype.interfaces import fsl\n",
    "    from os.path import abspath\n",
    "    merge = fsl.Merge(in_files= [ap, pa],\n",
    "                      dimension = 't', merged_file = 'AP_PA_merged.nii.gz').run()\n",
    "    merged_file = abspath('AP_PA_merged.nii.gz')\n",
    "    return merged_file\n",
    "\n",
    "create_merge = Node(Function(input_names=['ap', 'pa'],\n",
    "                             output_names=['merged_file'],\n",
    "                             function = create_merged_files),\n",
    "                    name='create_merge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "#Resample T1w to same voxel dimensions as DTI to avoid data interpolation (1.714286 x 1.714286 x 1.700001) .  \n",
    "resampt1 = Node(fsr.Resample(voxel_size = (1.714286, 1.714286, 1.700001)),\n",
    "               name='resampT1')\n",
    "\n",
    "#Drop bottom slice (S/I) to create even # of slices\n",
    "drop = Node(fsl.ExtractROI(x_min=0, x_size=140,\n",
    "                           y_min=0, y_size=140,\n",
    "                           z_min=1, z_size=80),\n",
    "           name='drop')\n",
    "\n",
    "#drop bottom slice of DTI file\n",
    "drop2 = drop.clone(name='drop2')\n",
    "\n",
    "#Denoise DWI data susing local PCA correction - mrTrix3\n",
    "denoise = Node(mtx.DWIDenoise(),\n",
    "              name='denoise')\n",
    "\n",
    "######################## Steps added 7/17 per Jiook's reccomendations\n",
    "##Gibbs ringing removal\n",
    "#gibbs = Node(mtx.MRDeGibbs(),\n",
    "#            name = 'gibbs')\n",
    "\n",
    "##DWI bias file correction\n",
    "#bias = Node(mtx.DWIBiasCorrect(),\n",
    "#          name='bias')\n",
    "\n",
    "###########################\n",
    "\n",
    "#Run topup on merged files from pe1 and pe0\n",
    "topup = Node(fsl.TOPUP(config = 'b02b0.cnf',\n",
    "                       out_corrected = 'ap_pa_topup.nii.gz'),\n",
    "            name = 'topup')\n",
    "\n",
    "#Select b0 image for registration\n",
    "fslroi = Node(fsl.ExtractROI(t_min = 0, \n",
    "                             t_size = 1, \n",
    "                             roi_file = 'b0_img.nii.gz'),\n",
    "              name = 'fslroi')\n",
    "\n",
    "#Reorient topup b0 image to std\n",
    "reorient1 = Node(fsl.Reorient2Std(output_type = 'NIFTI_GZ'),\n",
    "                    name = 'reorient1')\n",
    "\n",
    "#Register b0 to T1\n",
    "register1 = Node(fsl.FLIRT(out_matrix_file = 'b0toT1_reorient_reg.mat',\n",
    "                          output_type = 'NIFTI_GZ'),\n",
    "                    name = 'register1')\n",
    "\n",
    "#apply topup from merged file to rest of pe0 scan\n",
    "apptop = Node(fsl.ApplyTOPUP(method='jac',\n",
    "                            in_index=[2]),\n",
    "             name = 'apptop')\n",
    "\n",
    "#Skullstrip the T1w image\n",
    "stripT1 = Node(fsl.BET(mask = True),\n",
    "              name = 'stripT1')\n",
    "\n",
    "#Reorient DTI data to standard orientation\n",
    "reorient2 = Node(fsl.Reorient2Std(output_type = 'NIFTI_GZ'),\n",
    "                    name = 'reorient2')\n",
    "\n",
    "#Flirt node to register DTI data using transformation matrix from register1\n",
    "register2 = Node(fsl.FLIRT(output_type = 'NIFTI_GZ',\n",
    "                          apply_xfm=True),\n",
    "                    name = 'register2')\n",
    "\n",
    "#FSL Eddy correction to remove eddy current distortion\n",
    "eddy = Node(fsl.Eddy(is_shelled = True,\n",
    "                     cnr_maps=True,\n",
    "                     repol=True),\n",
    "           name = 'eddy')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preproc_flow = Workflow(name = 'preproc_flow')\n",
    "preproc_flow.connect([(infosource, sf, [('subject_id','subject_id')]),\n",
    "                      #Select AP and PA encoded fieldmaps; merge niftis\n",
    "                      (sf, create_merge, [('fmapap', 'ap'),\n",
    "                                         ('fmappa', 'pa')]),\n",
    "                      #Drop bottom slice of nifi (had odd # slices)\n",
    "                      (create_merge, drop, [('merged_file', 'in_file')]),\n",
    "                      #Run topop across merged niftis\n",
    "                      (drop, topup, [('roi_file', 'in_file')]),\n",
    "                      (sf, topup, [('aps','encoding_file')]),\n",
    "                      (topup, datasink,[('out_corrected', '1_Check_Unwarped.@par')]),\n",
    "                      #Extract b0 image from nifti with topup applied\n",
    "                      (topup, fslroi, [('out_corrected', 'in_file')]),\n",
    "                      #Reorient b0 to standard\n",
    "                      (fslroi, reorient1, [('roi_file', 'in_file')]),\n",
    "                      #Resample T1w to same voxel dimensions as DTI\n",
    "                      (sf,  resampt1, [('t1', 'in_file')]),\n",
    "                      (resampt1, stripT1, [('resampled_file','in_file')]),\n",
    "                      #Skull strip T1w, save stripped anat and mask\n",
    "                      (stripT1, datasink, [('mask_file', '1_Check_Unwarped.@par.@par.@par.@par.@par.@par'),\n",
    "                                          ('out_file', '1_Check_Unwarped.@par.@par.@par.@par.@par.@par.@par'),\n",
    "                                          ('out_file', 'preafq')]),\n",
    "                      #Register reoriented b0 to T1\n",
    "                      (stripT1, register1, [('out_file', 'reference')]),\n",
    "                      (reorient1, register1, [('out_file', 'in_file')]),\n",
    "                      (register1, datasink, [('out_file', '1_Check_Unwarped.@par.@par')]),\n",
    "                      #Apply transform generated in topup to DTI\n",
    "                      (topup, apptop, [('out_fieldcoef', 'in_topup_fieldcoef'),\n",
    "                                       ('out_movpar', 'in_topup_movpar')]),\n",
    "                      #Drop bottom slice from DTI nifti\n",
    "                      (sf, drop2, [('dti', 'in_file')]),\n",
    "                      #Local PCA to denoise DTI data\n",
    "                      (drop2, denoise, [('roi_file', 'in_file')]),\n",
    "                      (denoise, datasink, [('out_file', '1_Check_Unwarped.@par.@par.@par')]),\n",
    "                      #Gibbs ringing removal\n",
    "                      # (drop2, gibbs, [('roi_file','in_file')]),\n",
    "                      ##Perform DWI bias field correction\n",
    "                      #(gibbs, bias, [('out_file', 'in_file')]),\n",
    "                      #(sf, bias, [('bvec', 'in_bvec')]),\n",
    "                      #(sf, bias, [('bval', 'in_bval')]),\n",
    "                      #Apply topup to bias corrected DTI data\n",
    "                      (denoise, apptop, [('out_file', 'in_files')]),\n",
    "                      (sf, apptop, [('aps', 'encoding_file')]),\n",
    "                      (apptop, datasink, [('out_corrected', '1_Check_Unwarped.@par.@par.@par.@par.@par')]),\n",
    "                      #reorient DTI file with topup applied to standard\n",
    "                      (apptop, reorient2, [('out_corrected','in_file')]),\n",
    "                      (reorient2, datasink, [('out_file', '1_Check_Unwarped.@par.@par.@par.@par.@par.@par.@par.@par')]),\n",
    "                      #Register DTI to skullstripped, resampled T1w \n",
    "                      (reorient2, register2, [('out_file','in_file')]),\n",
    "                      (stripT1, register2, [('out_file','reference')]),\n",
    "                      #use xfm from b0 registration from T1 to apply to DTI nifti\n",
    "                      (register1, register2, [('out_matrix_file', 'in_matrix_file')]),\n",
    "                      (register2, datasink, [('out_file', '1_Check_Unwarped.@par.@par.@par.@par.@par.@par.@par.@par.@par')]),\n",
    "                      #Run eddy correction\n",
    "                       (sf, eddy, [('index', 'in_index'),\n",
    "                                  ('bvec', 'in_bvec'),\n",
    "                                  ('bval', 'in_bval'),\n",
    "                                  ('aps', 'in_acqp')]),\n",
    "                       (stripT1, eddy, [('mask_file', 'in_mask')]),\n",
    "                       (register2, eddy, [('out_file','in_file')]),\n",
    "                       (eddy, datasink,[('out_corrected','2_Eddy_Corrected'),\n",
    "                                        ('out_corrected', 'preafq.@par'),\n",
    "                                        ('out_rotated_bvecs','preafq.@par.@par'),\n",
    "                                        ('out_rotated_bvecs','2_Eddy_Corrected.@par'),\n",
    "                                        ('out_movement_rms','2_Eddy_Corrected.@par.@par'),\n",
    "                                        ('out_outlier_report','2_Eddy_Corrected.@par.@par.@par')]),\n",
    "                       #Save subject bval files to preafq dir\n",
    "                       (sf, datasink, [('bval', 'preafq.@par.@par.@par')])\n",
    "                     ])\n",
    "preproc_flow.base_dir = workflow_dir\n",
    "preproc_flow.write_graph(graph2use = 'flat')\n",
    "preproc = preproc_flow.run('MultiProc', plugin_args={'n_procs': 4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### \n",
    "\n",
    "# def organize_preafq(sub):\n",
    "\n",
    "\n",
    "# # Do all the things:\n",
    "# def run_AFQ(preafq):\n",
    "#     from AFQ import api\n",
    "#     myafq = api.AFQ(join(home,'preafq/'))   \n",
    "#     myafq.set_dti_cfa()\n",
    "#     myafq.set_dti_pdd()\n",
    "#     myafq.set_template_xform()\n",
    "#     myafq.export_rois()\n",
    "#     myafq.export_bundles()\n",
    "#     myafq.combine_profiles()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# myafq.combine_profiles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
