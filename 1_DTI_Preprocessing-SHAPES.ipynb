{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from nipype.interfaces.io import DataSink, SelectFiles, DataGrabber\n",
    "from nipype.interfaces.utility import IdentityInterface, Function\n",
    "from nipype.pipeline.engine import Node, Workflow, JoinNode, MapNode\n",
    "from nipype.interfaces import fsl\n",
    "from nipype.interfaces import ants\n",
    "import nipype.interfaces.mrtrix3 as mtx\n",
    "import nipype.interfaces.freesurfer as fsr\n",
    "import nipype.interfaces.freesurfer.model as fsrm\n",
    "from pandas import Series, read_csv, to_numeric\n",
    "from glob import glob\n",
    "from os.path import abspath, expanduser, join\n",
    "from os import chdir, remove, getcwd, makedirs\n",
    "from shutil import copyfile\n",
    "from nipype import config, logging\n",
    "from datetime import date\n",
    "import sys\n",
    "\n",
    "var1 = str(sys.argv[1])\n",
    "today = str(date.today())\n",
    "config.enable_debug_mode()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set variables\n",
    "user = expanduser('~')\n",
    "if user == '/Users/lucindasisk':\n",
    "    home = join(user, 'Desktop/Milgram/candlab')\n",
    "    raw_dir = join(home, 'data/mri/bids_recon/shapes')\n",
    "    workflow_dir = join(home, 'analyses/shapes/dwi/workflows')\n",
    "    data_dir = join(home, 'analyses/shapes/dwi/data')\n",
    "else:\n",
    "    home = '/gpfs/milgram/project/gee_dylan/candlab'\n",
    "    raw_dir = join(home, 'data/mri/bids_recon/shapes')\n",
    "    workflow_dir = join(home, 'analyses/shapes/dwi/workflows')\n",
    "    data_dir = join(home, 'analyses/shapes/dwi/data')\n",
    "    \n",
    "# Read in subject subject_list\n",
    "# subject_csv = read_csv(home + '/analyses/shapes/dwi/DTI_RI_SubjectList.csv', header=0)\n",
    "# sublist = 'sub-' + Series(subject_csv['subid'])\n",
    "# subject_list = sublist.values.tolist()\n",
    "subject_list = [var1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9/22/19: change so that T1 is registered to B0 per https://mrtrix.readthedocs.io/en/latest/quantitative_structural_connectivity/act.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create preprocessing Workflow\n",
    "\n",
    "# set default FreeSurfer subjects dir\n",
    "fsr.FSCommand.set_default_subjects_dir(raw_dir)\n",
    "\n",
    "# Setup Datasink, Infosource, Selectfiles\n",
    "\n",
    "datasink = Node(DataSink(base_directory=data_dir,\n",
    "                         substitutions=[('_subject_id_', '')]),\n",
    "                name='datasink')\n",
    "\n",
    "# Set infosource iterables\n",
    "infosource = Node(IdentityInterface(fields=['subject_id']),\n",
    "                  name=\"infosource\")\n",
    "infosource.iterables = [('subject_id', subject_list)]\n",
    "\n",
    "# SelectFiles\n",
    "template = dict(t1=join(raw_dir, '{subject_id}/ses-shapesV1/anat/{subject_id}_ses-shapesV1_T1w.nii.gz'),\n",
    "                dti=join(\n",
    "                    raw_dir, '{subject_id}/ses-shapesV1/dwi/{subject_id}_ses-shapesV1_dwi.nii.gz'),\n",
    "                bval=join(\n",
    "                    raw_dir, '{subject_id}/ses-shapesV1/dwi/{subject_id}_ses-shapesV1_dwi.bval'),\n",
    "                bvec=join(\n",
    "                    raw_dir, '{subject_id}/ses-shapesV1/dwi/{subject_id}_ses-shapesV1_dwi.bvec'),\n",
    "                fmappa=join(\n",
    "                    raw_dir, '{subject_id}/ses-shapesV1/fmap/{subject_id}_ses-shapesV1_acq-dwi_dir-PA_epi.nii.gz'),\n",
    "                fmapap=join(\n",
    "                    raw_dir, '{subject_id}/ses-shapesV1/fmap/{subject_id}_ses-shapesV1_acq-dwi_dir-AP_epi.nii.gz'),\n",
    "                aps=join(raw_dir, 'shapes_acqparams.txt'),\n",
    "                index=join(raw_dir, 'shapes_index.txt'),\n",
    "                mni=join(home, 'atlases/MNI152_T1_2mm_brain.nii.gz'),\n",
    "                mni_mask=join(home, 'atlases/MNI152_T1_2mm_brain_mask.nii.gz')\n",
    "                )\n",
    "\n",
    "sf = Node(SelectFiles(template,\n",
    "                      base_directory=home),\n",
    "          name='sf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge AP/PA encoding direction fieldmaps\n",
    "def create_merged_files(ap, pa):\n",
    "    from nipype.interfaces import fsl\n",
    "    from os.path import abspath\n",
    "    merge = fsl.Merge(in_files=[ap, pa],\n",
    "                      dimension='t', output_type='NIFTI_GZ', merged_file='AP_PA_merged.nii.gz').run()\n",
    "    merged_file = abspath('AP_PA_merged.nii.gz')\n",
    "    return merged_file\n",
    "\n",
    "\n",
    "create_merge = Node(Function(input_names=['ap', 'pa'],\n",
    "                             output_names=['merged_file'],\n",
    "                             function=create_merged_files),\n",
    "                    name='create_merge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### MRTrix Commands ###########################\n",
    "\n",
    "# Drop bottom slice (S/I) to create even # of slices\n",
    "drop = Node(fsl.ExtractROI(x_min=0, x_size=140,\n",
    "                           y_min=0, y_size=140,\n",
    "                           z_min=1, z_size=80, output_type='NIFTI_GZ'),\n",
    "            name='drop')\n",
    "\n",
    "# drop bottom slice of DTI file\n",
    "drop2 = drop.clone(name='drop2')\n",
    "\n",
    "# Denoise DWI data susing local PCA correction - mrTrix3\n",
    "denoise = Node(mtx.DWIDenoise(),\n",
    "               name='denoise')\n",
    "\n",
    "# Steps added 7/17 per Jiook's reccomendations\n",
    "# Gibbs ringing removal\n",
    "gibbs = Node(mtx.MRDeGibbs(),\n",
    "             name='gibbs')\n",
    "\n",
    "# DWI bias file correction using ANTS N4\n",
    "bias = Node(mtx.DWIBiasCorrect(use_ants=True),\n",
    "            name='bias')\n",
    "\n",
    "# Extract mask from DWI data\n",
    "dwimask = Node(mtx.BrainMask(bval_scale = 'yes'),\n",
    "              name = 'dwimask')\n",
    "\n",
    "########################### Standard/Other nodes ###########################\n",
    "\n",
    "# Run topup on merged files from pe1 and pe0\n",
    "topup = Node(fsl.TOPUP(config='b02b0.cnf',\n",
    "                       out_corrected='ap_pa_topup.nii.gz', output_type='NIFTI_GZ'),\n",
    "             name='topup')\n",
    "\n",
    "# Select b0 image for registration\n",
    "fslroi = Node(fsl.ExtractROI(t_min=0,\n",
    "                             t_size=1,\n",
    "                             roi_file='b0_img.nii.gz', output_type='NIFTI_GZ'),\n",
    "              name='fslroi')\n",
    "\n",
    "# Reorient topup b0 image to std\n",
    "reorient1 = Node(fsl.Reorient2Std(output_type='NIFTI_GZ'),\n",
    "                 name='reorient1')\n",
    "\n",
    "# Register T1 to b0 - rigid 2D transformation\n",
    "register1 = Node(fsl.FLIRT(out_matrix_file='b0toT1_reorient_reg.mat',\n",
    "                           rigid2D=True,\n",
    "                           output_type='NIFTI_GZ'),\n",
    "                 name='register1')\n",
    "\n",
    "# apply topup from merged file to rest of pe0 scan\n",
    "apptop = Node(fsl.ApplyTOPUP(method='jac',\n",
    "                             in_index=[2], \n",
    "                             output_type='NIFTI_GZ',\n",
    "                            out_corrected = 'preprocessed_dwi.nii.gz'),\n",
    "              name='apptop')\n",
    "\n",
    "# Skullstrip the T1w image\n",
    "stripT1 = Node(fsl.BET(mask=True, output_type='NIFTI_GZ'),\n",
    "               name='stripT1')\n",
    "\n",
    "# Skullstrip the b0 image\n",
    "stripb0 = Node(fsl.BET(mask=True, output_type='NIFTI_GZ'),\n",
    "               name='stripb0')\n",
    "\n",
    "#Eddy_CUDA Node\n",
    "# FSL Eddy correction to remove eddy current distortion\n",
    "\n",
    "eddy = Node(fsl.Eddy(is_shelled=True,\n",
    "                     interp='trilinear',\n",
    "                     method='jac',\n",
    "                     output_type='NIFTI_GZ',\n",
    "                     residuals=True,\n",
    "                     use_cuda=True,\n",
    "                     cnr_maps=True,\n",
    "                     repol=True),\n",
    "            name='eddy')\n",
    "\n",
    "#Upsample dti to isotropic 1x1x1\n",
    "resample = Node(fsr.Resample(voxel_size=(1, 1, 1)),\n",
    "               name = \"resample\")\n",
    "\n",
    "#Upsample dti to isotropic 1x1x1\n",
    "resample2 = Node(fsr.Resample(voxel_size=(1, 1, 1)),\n",
    "               name = \"resample2\")\n",
    "\n",
    "#Register DTI to MNI brain\n",
    "registermni = Node(fsl.FLIRT(out_matrix_file='b0toMNI_registered.mat',\n",
    "                           rigid2D=True,\n",
    "                           output_type='NIFTI_GZ'),\n",
    "                 name='registermni')\n",
    "\n",
    "applyreg_mni = Node(fsl.FLIRT(out_matrix_file='b0toMNI_registered.mat',\n",
    "                             rigid2D=True,\n",
    "                             output_type='NIFTI_GZ',\n",
    "                             apply_xfm = True),\n",
    "                 name='applyreg_mni')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preproc_flow = Workflow(name='preproc_flow')\n",
    "preproc_flow.connect([(infosource, sf, [('subject_id', 'subject_id')]),\n",
    "                      \n",
    "                      # Select AP and PA encoded fieldmaps; merge niftis\n",
    "                      (sf, create_merge, [('fmapap', 'ap'),\n",
    "                                          ('fmappa', 'pa')]),\n",
    "                      \n",
    "                      # Drop bottom slice of nifi (had odd # slices)\n",
    "                      (create_merge, drop, [('merged_file', 'in_file')]),\n",
    "                      \n",
    "                      # Run topop across merged niftis\n",
    "                      (drop, topup, [('roi_file', 'in_file')]),\n",
    "                      (sf, topup, [('aps', 'encoding_file')]),\n",
    "                      \n",
    "                      #Select data, drop bottom slice (odd # slices)\n",
    "                      (sf, drop2, [('dti', 'in_file')]),\n",
    "                      \n",
    "                      # denoise\n",
    "                      (drop2, denoise, [('roi_file', 'in_file')]),\n",
    "                      \n",
    "                      # Gibbs ringing removal (in this order per https://mrtrix.readthedocs.io/en/latest/reference/commands/mrdegibbs.html)\n",
    "                      (denoise, gibbs, [('out_file', 'in_file')]),\n",
    "                      \n",
    "                      # Apply topup to bias/Gibbs corrected DTI data\n",
    "                      (topup, apptop, [('out_fieldcoef', 'in_topup_fieldcoef'),\n",
    "                                      ('out_movpar','in_topup_movpar')]),\n",
    "                      (gibbs, apptop, [('out_file', 'in_files')]),\n",
    "                      (sf, apptop, [('aps', 'encoding_file')]),\n",
    "                      \n",
    "                      # Perform B1 field inhomogeneity correction for a DWI volume series.\n",
    "                      (apptop, bias, [('out_corrected', 'in_file')]),\n",
    "                      \n",
    "                      # Extract b0 image from nifti with topup applied\n",
    "                      (bias, fslroi, [('out_file', 'in_file')]),\n",
    "                      \n",
    "                      # Skullstrip T1 and b0\n",
    "                      (sf, stripT1, [('t1', 'in_file')]),\n",
    "                      (fslroi, stripb0, [('roi_file', 'in_file')]),\n",
    "                      \n",
    "                      #Register b0 to MNI\n",
    "                      (stripb0, registermni, [('out_file', 'in_file')]),\n",
    "                      (sf, registermni, [('mni', 'reference')]),\n",
    "                      (registermni, datasink, [('out_file', 'Preprocessed_Data')]),\n",
    "                      \n",
    "                      #Apply transform to dwi data\n",
    "                      (registermni, applyreg_mni, [('out_matrix_file', 'in_matrix_file')]),\n",
    "                      (sf, applyreg_mni, [('mni', 'reference')]),\n",
    "                      (bias, applyreg_mni, [('out_file', 'in_file')]),\n",
    "                      (applyreg_mni, datasink, [('out_file', 'Preprocessed_Data.@par')]),\n",
    "                      \n",
    "                      # Register T1 to MNI-registered b0 ]\n",
    "                      (stripT1, register1, [('out_file', 'in_file')]),\n",
    "                      (registermni, register1, [('out_file', 'reference')]),\n",
    "                      (register1, datasink, [('out_file', 'Preprocessed_Data.@par.@par')]),\n",
    "                      \n",
    "                      # Create analysis mask for next steps\n",
    "                      (applyreg_mni, dwimask, [('out_file', 'in_file')]),\n",
    "                      (sf, dwimask, [('bval', 'in_bval'),\n",
    "                                     ('bvec', 'in_bvec')]),\n",
    "                      \n",
    "                      #Resample DTI to uniform dimensions 1x1x1\n",
    "                      (applyreg_mni, resample, [('out_file', 'in_file')]),\n",
    "                      \n",
    "                      #Resample mask file 1x1x1\n",
    "                      (dwimask, resample2, [('out_file', 'in_file')]),\n",
    "                      \n",
    "                      #Pass in resampled outputs to Eddy\n",
    "                      (resample, eddy, [('resampled_file', 'in_file')]),\n",
    "                      (sf, eddy,[('bval', 'in_bval'),\n",
    "                                 ('bvec', 'in_bvec'),\n",
    "                                 ('index', 'in_index'),\n",
    "                                 ('aps', 'in_acqp')]),\n",
    "                      (resample2, eddy, [('resampled_file', 'in_mask')]),\n",
    "                      \n",
    "                      #Save Eddy outputs\n",
    "                      (eddy, datasink, [('out_corrected', 'Preprocessed_Data.@par.@par.@par'),\n",
    "                                        ('out_rotated_bvecs', 'Preprocessed_Data.@par.@par.@par.@par'),\n",
    "                                        ('out_movement_rms',\n",
    "                                         'Preprocessed_Data.@par.@par.@par.@par.@par'),\n",
    "                                        ('out_parameter',\n",
    "                                         'Preprocessed_Data.@par.@par.@par.@par.@par.@par'),\n",
    "                                        ('out_restricted_movement_rms',\n",
    "                                         'Preprocessed_Data.@par.@par.@par.@par.@par.@par.@par'),\n",
    "                                        ('out_shell_alignment_parameters',\n",
    "                                         'Preprocessed_Data.@par.@par.@par.@par.@par.@par.@par.@par'),\n",
    "                                        ('out_cnr_maps',\n",
    "                                         'Preprocessed_Data.@par.@par.@par.@par.@par.@par.@par.@par.@par'),\n",
    "                                        ('out_residuals',\n",
    "                                         'Preprocessed_Data.@par.@par.@par.@par.@par.@par.@par.@par.@par.@par'),\n",
    "                                        ('out_outlier_report',\n",
    "                                         'Preprocessed_Data.@par.@par.@par.@par.@par.@par.@par.@par.@par.@par.@par')]),\n",
    "                     ])\n",
    "\n",
    "preproc_flow.base_dir = workflow_dir\n",
    "preproc_flow.write_graph(graph2use='flat')\n",
    "preproc = preproc_flow.run('MultiProc', plugin_args={'n_procs': 4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
