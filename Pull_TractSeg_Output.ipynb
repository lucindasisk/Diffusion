{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "worst-median",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "\n",
    "today=str(date.today())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "invalid-petroleum",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data paths\n",
    "candpath = '/gpfs/milgram/pi/gee_dylan/candlab'\n",
    "data = candpath + '/analyses/shapes/dwi/data'\n",
    "\n",
    "# Import subjects\n",
    "subs = ri_sublist = pd.read_csv(data + '/../subjectlist_preDiss_motion0.75_n116_2021-03-23.csv', names = ['index', 'Subject'], header = 0)\n",
    "subs['Subject'] = 'sub-' + subs['Subject']\n",
    "\n",
    "#DTI Column Names\n",
    "colnames_dti = ['AF_left', 'AF_right', 'ATR_left', 'ATR_right', 'CC_1', 'CC_2', 'CC_3',\n",
    "       'CC_4', 'CC_5', 'CC_6', 'CC_7', 'CG_left', 'CG_right', 'CST_left',\n",
    "       'CST_right', 'FPT_left', 'FPT_right', 'ICP_left', 'ICP_right',\n",
    "       'IFO_left', 'IFO_right', 'ILF_left', 'ILF_right', 'MCP', 'OR_left',\n",
    "       'OR_right', 'POPT_left', 'POPT_right', 'SCP_left', 'SCP_right',\n",
    "       'SLF_I_left', 'SLF_I_right', 'SLF_II_left', 'SLF_II_right',\n",
    "       'SLF_III_left', 'SLF_III_right', 'STR_left', 'STR_right', 'UF_left',\n",
    "       'UF_right', 'T_PREM_left', 'T_PREM_right', 'T_PAR_left', 'T_PAR_right',\n",
    "       'T_OCC_left', 'T_OCC_right', 'ST_FO_left', 'ST_FO_right',\n",
    "       'ST_PREM_left', 'ST_PREM_right']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minus-quarterly",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "protecting-savannah",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import demographic data\n",
    "demo_raw = pd.read_csv(data + '/Analysis/Behavioral/Demographic_Info.csv', \n",
    "                   header = 0).rename(columns = {'subj_id':'Subject', 'branch_a_sex':'sex'})\n",
    "demo = demo_raw[['Subject', 'sex', 'asr_age']].set_index('Subject')\n",
    "\n",
    "diag = pd.read_csv(data + '/Analysis/Behavioral/DiagnosticStatus.csv', \n",
    "                   header = 0).rename(columns = {'record_id':'Subject', 'cc_group':'diagnostic_group'})\n",
    "diag_only = diag[['Subject', 'diagnostic_group']].set_index('Subject')\n",
    "\n",
    "demo_data = pd.concat([demo, diag_only], axis=1).reset_index()\n",
    "demo_data['Subject'] = 'sub-' + demo_data['Subject']\n",
    "\n",
    "#Import RI data (Wide)\n",
    "ri1 = pd.read_csv(data + '/Analysis/Behavioral/Cleaned_WIDE_threat_endorsements_2021-03-26.csv', \n",
    "                  header = 0).rename(columns = {'Unnamed: 0':'Subject'}).drop([0,1], axis=0)\n",
    "ri1.columns = 'threat_' + ri1.columns\n",
    "ri1 = ri1.rename(columns = {'threat_Subject':'Subject'}).set_index('Subject')\n",
    "\n",
    "ri2 = pd.read_csv(data + '/Analysis/Behavioral/Cleaned_WIDE_dep_endorsements_2021-03-26.csv', \n",
    "                  header = 0).rename(columns = {'Unnamed: 0':'Subject'}).drop([0,1], axis=0)\n",
    "ri2.columns = 'dep_' + ri2.columns\n",
    "ri2 = ri2.rename(columns = {'dep_Subject':'Subject'}).set_index('Subject')\n",
    "\n",
    "ri3 = pd.read_csv(data + '/Analysis/Behavioral/Cleaned_WIDE_any_endorsements_2021-03-26.csv', \n",
    "                  header = 0).rename(columns = {'Unnamed: 0':'Subject'}).drop([0,1], axis=0)\n",
    "ri3.columns = 'all_' + ri3.columns\n",
    "ri3 = ri3.rename(columns = {'all_Subject':'Subject'}).set_index('Subject')\n",
    "\n",
    "ri_data = pd.concat([ri1, ri2, ri3], axis=1).reset_index()\n",
    "ri_data['Subject'] = 'sub-' + ri_data['Subject']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "retired-fault",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import RI data (long)\n",
    "ri4 = pd.read_csv(data + '/Analysis/Behavioral/Cleaned_threat_endorsements_2021-03-26.csv',\n",
    "                  header = 0).rename(columns = {'ucla_a_id':'Subject'})\n",
    "ri4.columns = 'threat_' + ri4.columns\n",
    "ri4 = ri4.rename(columns = {'threat_Subject':'Subject'})\n",
    "ri4['Subject'] = 'sub-' + ri4['Subject']\n",
    "\n",
    "ri5 = pd.read_csv(data + '/Analysis/Behavioral/Cleaned_dep_endorsements_2021-03-26.csv',\n",
    "                  header = 0).rename(columns = {'ucla_a_id':'Subject'})\n",
    "ri5.columns = 'dep_' + ri5.columns\n",
    "ri5 = ri5.rename(columns = {'dep_Subject':'Subject'})\n",
    "ri5['Subject'] = 'sub-' + ri5['Subject']\n",
    "\n",
    "ri6 = pd.read_csv(data + '/Analysis/Behavioral/Cleaned_all_endorsements_2021-03-26.csv',\n",
    "                  header = 0).rename(columns = {'ucla_a_id':'Subject'})\n",
    "ri6.columns = 'all_' + ri6.columns\n",
    "ri6 = ri6.rename(columns = {'all_Subject':'Subject'})\n",
    "ri6['Subject'] = 'sub-' + ri6['Subject']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "diagnostic-bench",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge data together\n",
    "m1 = pd.merge(subs['Subject'], demo_data, how = 'left', on='Subject').dropna(how = 'any', axis=0)\n",
    "m2 = pd.merge(m1, ri_data, how = 'left', on='Subject')\n",
    "\n",
    "bx_df = m2\n",
    "bx_df.shape\n",
    "\n",
    "long_thr_df = pd.merge(m1, ri4, how = 'inner', on = 'Subject')\n",
    "long_dep_df = pd.merge(m1, ri5, how = 'inner', on = 'Subject')\n",
    "long_all_df = pd.merge(m1, ri6, how = 'inner', on = 'Subject')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ceramic-montana",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_tract_means(sub_df):\n",
    "    output = np.ones((len(sub_df), 50), dtype='object')\n",
    "    for i in range(0, len(sub_df)):\n",
    "        sub = sub_df['Subject'][i]\n",
    "        try:\n",
    "            rawdata = pd.read_csv(data + '/tract_output/{}/Tractometry_{}.csv'.format(sub, sub), header = 0, sep = ';')\n",
    "            column_names = rawdata.columns\n",
    "            means = rawdata.mean(axis=0)\n",
    "            output[i,:] = means\n",
    "        except:\n",
    "            print(\"No output for {}\".format(sub))\n",
    "            output[i,:] = np.nan\n",
    "    output_df = pd.concat([sub_df['Subject'], pd.DataFrame(output, columns = column_names)], axis=1)\n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "thirty-athletics",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_uf(sub_df):\n",
    "    l_output = np.ones((len(sub_df), 98), dtype='object')\n",
    "    r_output = np.ones((len(sub_df), 98), dtype='object')\n",
    "    for i in range(0, len(sub_df)):\n",
    "        sub = sub_df['Subject'][i]\n",
    "        try:\n",
    "            rawdata = pd.read_csv(data + '/tract_output/{}/Tractometry_{}.csv'.format(sub, sub), header = 0, sep = ';')\n",
    "            luf_data = rawdata['UF_left']\n",
    "            ruf_data = rawdata['UF_right']\n",
    "            l_output[i, :] = luf_data\n",
    "            r_output[i, :] = ruf_data\n",
    "        except:\n",
    "            print(\"No output for {}\".format(sub))\n",
    "            output[i,:] = np.nan\n",
    "    l_output_df = pd.concat([sub_df['Subject'], pd.DataFrame(l_output)], axis=1)\n",
    "    r_output_df = pd.concat([sub_df['Subject'], pd.DataFrame(r_output)], axis=1)\n",
    "    return l_output_df, r_output_df\n",
    "\n",
    "luf_df, ruf_df = extract_uf(bx_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "enclosed-rainbow",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regress_covariates(dti_df, behav_df):\n",
    "    regressed_output = np.ones((len(dti_df), len(dti_df.columns)-1))\n",
    "    \n",
    "    regressors = behav_df[['sex', 'asr_age', 'diagnostic_group']]\n",
    "    regressors['sex'] = regressors['sex'].astype('category')\n",
    "    regressors['asr_age'] = regressors['asr_age'].astype(float)\n",
    "    regressors['diagnostic_group'] = regressors['diagnostic_group'].astype('category')\n",
    "    regressors = sm.add_constant(regressors) #Add intercept for OLS regression per https://www.statsmodels.org/stable/examples/notebooks/generated/ols.html\n",
    "    for i in range(0, len(dti_df.columns)-1):\n",
    "        #Set variables and ensure dtype\n",
    "        sub = behav_df['Subject'][i]\n",
    "        dti_col = dti_df.drop('Subject', axis=1).to_numpy()[:,i].astype(float)\n",
    "        model = sm.OLS(endog = dti_col, exog=regressors)\n",
    "        result = model.fit()\n",
    "        regressed_output[:,i] = result.resid\n",
    "    \n",
    "    return regressed_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "selective-trick",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/milgram/project/gee_dylan/lms233/conda_envs/mybrainiak/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n",
      "/gpfs/milgram/project/gee_dylan/lms233/conda_envs/mybrainiak/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/gpfs/milgram/project/gee_dylan/lms233/conda_envs/mybrainiak/lib/python3.7/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "#Compute tract means\n",
    "mean_df = compute_tract_means(bx_df).dropna(axis=0) #Input is bxdf so that subjects will be in same order\n",
    "\n",
    "#Regress age, sex, and diagnostic group from dti\n",
    "resid_mat = regress_covariates(mean_df, bx_df)\n",
    "resid_df = pd.DataFrame(pd.concat([mean_df['Subject'], pd.DataFrame(resid_mat, columns = colnames_dti)], axis=1))\n",
    "\n",
    "#Merge with long dfs\n",
    "long_thr_df_dwi = pd.merge(long_thr_df, resid_df, on='Subject', how = 'inner')\n",
    "long_dep_df_dwi = pd.merge(long_dep_df, resid_df, on='Subject', how = 'inner')\n",
    "long_all_df_dwi = pd.merge(long_all_df, resid_df, on='Subject', how = 'inner')\n",
    "\n",
    "#Extract specific tracts\n",
    "left_uf = resid_mat[:, 38]\n",
    "right_uf = resid_mat[:, 39]\n",
    "\n",
    "# #Prepare bx data for CCA\n",
    "bx_mat = bx_df.drop(['all_Summed_All', 'diagnostic_group', 'asr_age', 'sex', 'Subject'], \n",
    "                    axis=1).replace(np.nan, 0).to_numpy()\n",
    "bx_all = bx_df[['all_Summed_All']].replace(np.nan, 0).to_numpy().reshape(len(bx_df), )\n",
    "\n",
    "subids = mean_df['Subject']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "governing-matter",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "diagnostic-companion",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_df = pd.melt(resid_df, id_vars = 'Subject', var_name = 'Tract', value_name = 'Value')\n",
    "plotdf_long = pd.merge(long_df, bx_df)\n",
    "plotdf_wide = pd.merge(resid_df, bx_df)\n",
    "\n",
    "# Clean outliers\n",
    "cleaned = plotdf_wide[plotdf_wide['UF_left'] > -0.3]\n",
    "cleaned = cleaned[cleaned['threat_Summed_All'] < 700]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "rough-router",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Subject', 'AF_left', 'AF_right', 'ATR_left', 'ATR_right', 'CC_1',\n",
       "       'CC_2', 'CC_3', 'CC_4', 'CC_5', 'CC_6', 'CC_7', 'CG_left', 'CG_right',\n",
       "       'CST_left', 'CST_right', 'FPT_left', 'FPT_right', 'ICP_left',\n",
       "       'ICP_right', 'IFO_left', 'IFO_right', 'ILF_left', 'ILF_right', 'MCP',\n",
       "       'OR_left', 'OR_right', 'POPT_left', 'POPT_right', 'SCP_left',\n",
       "       'SCP_right', 'SLF_I_left', 'SLF_I_right', 'SLF_II_left', 'SLF_II_right',\n",
       "       'SLF_III_left', 'SLF_III_right', 'STR_left', 'STR_right', 'UF_left',\n",
       "       'UF_right', 'T_PREM_left', 'T_PREM_right', 'T_PAR_left', 'T_PAR_right',\n",
       "       'T_OCC_left', 'T_OCC_right', 'ST_FO_left', 'ST_FO_right',\n",
       "       'ST_PREM_left', 'ST_PREM_right'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resid_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "numerous-expense",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='dep_Summed_Dep', ylabel='UF_left'>"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Boxplots\n",
    "sns.regplot(x=cleaned['dep_Summed_Dep'], y = cleaned['UF_left'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "failing-smooth",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='sex', ylabel='UF_left'>"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(x=cleaned['sex'], y = cleaned['UF_left'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legitimate-constitutional",
   "metadata": {},
   "source": [
    "### OLS/LME Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "color-emperor",
   "metadata": {},
   "outputs": [],
   "source": [
    "yvar = 'UF_left'\n",
    "# long_thr_df_dwi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "wired-spain",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Mixed Linear Model Regression Results\n",
      "===================================================================\n",
      "Model:                  MixedLM     Dependent Variable:     UF_left\n",
      "No. Observations:       93          Method:                 REML   \n",
      "No. Groups:             93          Scale:                  0.0086 \n",
      "Min. group size:        1           Log-Likelihood:         31.5703\n",
      "Max. group size:        1           Converged:              Yes    \n",
      "Mean group size:        1.0                                        \n",
      "-------------------------------------------------------------------\n",
      "                         Coef.  Std.Err.   z    P>|z| [0.025 0.975]\n",
      "-------------------------------------------------------------------\n",
      "Intercept                -0.012    0.075 -0.158 0.875 -0.158  0.135\n",
      "threat_Summed_Threat      0.000    0.000  0.420 0.674 -0.001  0.001\n",
      "sex                       0.006    0.032  0.172 0.864 -0.058  0.069\n",
      "threat_Summed_Threat:sex -0.000    0.000 -0.394 0.694 -0.001  0.001\n",
      "asr_age                   0.000    0.002  0.174 0.862 -0.003  0.004\n",
      "diagnostic_group         -0.001    0.019 -0.036 0.971 -0.038  0.037\n",
      "Subject Var               0.009                                    \n",
      "===================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/milgram/project/gee_dylan/lms233/conda_envs/mybrainiak/lib/python3.7/site-packages/statsmodels/regression/mixed_linear_model.py:2237: ConvergenceWarning: The MLE may be on the boundary of the parameter space.\n",
      "  warnings.warn(msg, ConvergenceWarning)\n",
      "/gpfs/milgram/project/gee_dylan/lms233/conda_envs/mybrainiak/lib/python3.7/site-packages/statsmodels/regression/mixed_linear_model.py:2261: ConvergenceWarning: The Hessian matrix at the estimated parameter values is not positive definite.\n",
      "  warnings.warn(msg, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "lme_mod = sm.MixedLM.from_formula(\"{} ~ threat_Summed_Threat * sex + asr_age + sex + diagnostic_group\".format(yvar), \n",
    "                                 re_formula=\"1\", \n",
    "                groups=\"Subject\", data=plotdf_wide.replace(np.nan, 0))\n",
    "results = lme_mod.fit()\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "static-audio",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:                      y   R-squared (uncentered):                   0.001\n",
      "Model:                            OLS   Adj. R-squared (uncentered):             -0.044\n",
      "Method:                 Least Squares   F-statistic:                            0.03019\n",
      "Date:                Fri, 26 Mar 2021   Prob (F-statistic):                       0.998\n",
      "Time:                        20:16:44   Log-Likelihood:                          60.079\n",
      "No. Observations:                  93   AIC:                                     -112.2\n",
      "Df Residuals:                      89   BIC:                                     -102.0\n",
      "Df Model:                           4                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "====================================================================================\n",
      "                       coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------\n",
      "asr_age              0.0001      0.001      0.068      0.946      -0.003       0.003\n",
      "sex                  0.0015      0.027      0.055      0.956      -0.052       0.055\n",
      "diagnostic_group     0.0005      0.019      0.025      0.980      -0.037       0.038\n",
      "all_Summed_All   -3.237e-05   9.31e-05     -0.348      0.729      -0.000       0.000\n",
      "==============================================================================\n",
      "Omnibus:                       89.933   Durbin-Watson:                   0.727\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              635.273\n",
      "Skew:                          -3.348   Prob(JB):                    1.13e-138\n",
      "Kurtosis:                      13.914   Cond. No.                         385.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] RÂ² is computed without centering (uncentered) since the model does not contain a constant.\n",
      "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "regressors = bx_df[['asr_age', 'sex', 'diagnostic_group', 'all_Summed_All']].replace(np.nan, 0)\n",
    "model = sm.OLS(endog = right_uf, exog=regressors)\n",
    "result = model.fit()\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rubber-bhutan",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressors = plotdf_wide[['Subject', 'asr_age', 'sex', 'diagnostic_group']].replace(np.nan, 0)\n",
    "reg_all = pd.merge(regressors, luf_df, on = 'Subject').drop('Subject', axis=1).to_numpy().astype(float)\n",
    "yvar = plotdf_wide['all_Summed_All'].to_numpy().astype(float)\n",
    "\n",
    "regression = Ridge(normalize = True, alpha=1.0)\n",
    "regfit = regression.fit(reg_all, yvar)\n",
    "regfit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "divine-wound",
   "metadata": {},
   "source": [
    "### Ridge Regression Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "favorite-israel",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import Ridge\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "def perform_cv(subids, neural_data, bx_data):\n",
    "    numbers1 = pd.Series(range(0, len(neural_data))).to_numpy()\n",
    "    reg_corr = []\n",
    "    reg_p = []\n",
    "    r2 = []\n",
    "    for i in range(0, 50):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(neural_data, bx_data, test_size=0.33, random_state=i)\n",
    "\n",
    "        # Train the model \n",
    "        regression = Ridge(normalize = True, alpha=1.0)\n",
    "        regfit = regression.fit(X_train, y_train)\n",
    "\n",
    "        # Test the model\n",
    "        score = regfit.predict(X_test)\n",
    "        corr, p = spearmanr(score, y_test)\n",
    "        reg_corr.append(corr)\n",
    "        reg_p.append(p)\n",
    "        print('Correlation between train and test: {}'.format(corr))\n",
    "        print('P-value: {}'.format(p))\n",
    "        score = regfit.score(X_test, y_test)\n",
    "        r2.append(score)\n",
    "    return reg_corr, reg_p, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "primary-vector",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between train and test: -0.13470397652008118\n",
      "P-value: 0.46999802366069476\n",
      "Correlation between train and test: -0.38728576730731273\n",
      "P-value: 0.03135766126120925\n",
      "Correlation between train and test: 0.11111290174962021\n",
      "P-value: 0.5517933823786652\n",
      "Correlation between train and test: -0.14274358180973107\n",
      "P-value: 0.4436537859431303\n",
      "Correlation between train and test: 0.10178590634727984\n",
      "P-value: 0.585857059914406\n",
      "Correlation between train and test: 0.031765500078723\n",
      "P-value: 0.8652953590380698\n",
      "Correlation between train and test: 0.08434848016029564\n",
      "P-value: 0.6518895647229738\n",
      "Correlation between train and test: -0.3424746554556003\n",
      "P-value: 0.05930275123488388\n",
      "Correlation between train and test: -0.1387970258216814\n",
      "P-value: 0.4564848114587098\n",
      "Correlation between train and test: -0.303288044104304\n",
      "P-value: 0.0972022762311742\n",
      "Correlation between train and test: -0.4795969382663557\n",
      "P-value: 0.006331768962323641\n",
      "Correlation between train and test: -0.05645730445064192\n",
      "P-value: 0.7629082041055409\n",
      "Correlation between train and test: -0.31464302680987744\n",
      "P-value: 0.08471483827112292\n",
      "Correlation between train and test: -0.21087120040073906\n",
      "P-value: 0.2548304690492917\n",
      "Correlation between train and test: 0.0010090822493676725\n",
      "P-value: 0.995701465071436\n",
      "Correlation between train and test: -0.24967278405824322\n",
      "P-value: 0.17555782474859022\n",
      "Correlation between train and test: -0.3030873829167329\n",
      "P-value: 0.09743482646345919\n",
      "Correlation between train and test: 0.13737401770055685\n",
      "P-value: 0.4611592585468488\n",
      "Correlation between train and test: -0.2026413963317683\n",
      "P-value: 0.27426809374700306\n",
      "Correlation between train and test: -0.2895423790117841\n",
      "P-value: 0.1141270022527294\n",
      "Correlation between train and test: -0.37697046621946917\n",
      "P-value: 0.03657691014706195\n",
      "Correlation between train and test: -0.07462687174336836\n",
      "P-value: 0.6899026762839496\n",
      "Correlation between train and test: -0.09347554800235687\n",
      "P-value: 0.616962564573347\n",
      "Correlation between train and test: 0.08121228693474095\n",
      "P-value: 0.664064869019138\n",
      "Correlation between train and test: -0.17396874033060974\n",
      "P-value: 0.34928523691229896\n",
      "Correlation between train and test: -0.1585589218397865\n",
      "P-value: 0.3942427682356384\n",
      "Correlation between train and test: -0.13549753068154058\n",
      "P-value: 0.46736186616330677\n",
      "Correlation between train and test: -0.21208776501843565\n",
      "P-value: 0.25203616586776467\n",
      "Correlation between train and test: -0.048888988652256986\n",
      "P-value: 0.7939595062506508\n",
      "Correlation between train and test: -0.13232252899034935\n",
      "P-value: 0.4779555937271115\n",
      "Correlation between train and test: -0.3212917881986669\n",
      "P-value: 0.07799649092261746\n",
      "Correlation between train and test: 0.06417763105978397\n",
      "P-value: 0.7316016374488046\n",
      "Correlation between train and test: -0.5137108579610045\n",
      "P-value: 0.0031176632050642934\n",
      "Correlation between train and test: 0.06805874411169552\n",
      "P-value: 0.7160183623059382\n",
      "Correlation between train and test: -0.24950076180984423\n",
      "P-value: 0.175865352039769\n",
      "Correlation between train and test: -0.43715221929230136\n",
      "P-value: 0.013928735907273063\n",
      "Correlation between train and test: -0.05078433452076098\n",
      "P-value: 0.7861521721880211\n",
      "Correlation between train and test: -0.425051372414664\n",
      "P-value: 0.017143460366238608\n",
      "Correlation between train and test: -0.1670748741636625\n",
      "P-value: 0.3690023454766408\n",
      "Correlation between train and test: 0.01740021023420496\n",
      "P-value: 0.9259783192740376\n",
      "Correlation between train and test: -0.21339251433644252\n",
      "P-value: 0.24906188315163613\n",
      "Correlation between train and test: -0.1592331789502187\n",
      "P-value: 0.39220904227905884\n",
      "Correlation between train and test: -0.3002026327985698\n",
      "P-value: 0.10082474757072617\n",
      "Correlation between train and test: -0.04238145447344224\n",
      "P-value: 0.8209101957543542\n",
      "Correlation between train and test: 0.08804713110322947\n",
      "P-value: 0.6376430429614101\n",
      "Correlation between train and test: -0.1617587868599498\n",
      "P-value: 0.38464493988657755\n",
      "Correlation between train and test: 0.10828304924632128\n",
      "P-value: 0.562030460487284\n",
      "Correlation between train and test: -0.38506578635870387\n",
      "P-value: 0.032426460490324716\n",
      "Correlation between train and test: 0.06029375174177997\n",
      "P-value: 0.7473017181407788\n",
      "Correlation between train and test: -0.16914622971855053\n",
      "P-value: 0.3630103835625039\n"
     ]
    }
   ],
   "source": [
    "corr, pvals, r2_list = perform_cv(subids, l_, l_uf_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cellular-investigation",
   "metadata": {},
   "source": [
    "### CCA Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "internal-criterion",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_decomposition import CCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "permanent-olympus",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           AF_left\n",
       "1          AF_right\n",
       "2          ATR_left\n",
       "3         ATR_right\n",
       "4              CC_1\n",
       "5              CC_2\n",
       "6              CC_3\n",
       "7              CC_4\n",
       "8              CC_5\n",
       "9              CC_6\n",
       "10             CC_7\n",
       "11          CG_left\n",
       "12         CG_right\n",
       "13         CST_left\n",
       "14        CST_right\n",
       "15         FPT_left\n",
       "16        FPT_right\n",
       "17         ICP_left\n",
       "18        ICP_right\n",
       "19         IFO_left\n",
       "20        IFO_right\n",
       "21         ILF_left\n",
       "22        ILF_right\n",
       "23              MCP\n",
       "24          OR_left\n",
       "25         OR_right\n",
       "26        POPT_left\n",
       "27       POPT_right\n",
       "28         SCP_left\n",
       "29        SCP_right\n",
       "30       SLF_I_left\n",
       "31      SLF_I_right\n",
       "32      SLF_II_left\n",
       "33     SLF_II_right\n",
       "34     SLF_III_left\n",
       "35    SLF_III_right\n",
       "36         STR_left\n",
       "37        STR_right\n",
       "38          UF_left\n",
       "39         UF_right\n",
       "40      T_PREM_left\n",
       "41     T_PREM_right\n",
       "42       T_PAR_left\n",
       "43      T_PAR_right\n",
       "44       T_OCC_left\n",
       "45      T_OCC_right\n",
       "46       ST_FO_left\n",
       "47      ST_FO_right\n",
       "48     ST_PREM_left\n",
       "49    ST_PREM_right\n",
       "dtype: object"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(colnames_dti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "cooperative-mitchell",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CCA(n_components=6)"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cca = CCA(n_components=6, scale = True, copy = True)\n",
    "cca.fit(X = bx_mat, Y = resid_df)\n",
    "# CCA(n_components=1)\n",
    "# X_c, Y_c = cca.transform(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "shaped-driving",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.170856</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.359382</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.103717</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.230141</td>\n",
       "      <td>0.113409</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.266683</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.295407</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.240805</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.109448</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.226080</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.136623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.130642</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.308734</td>\n",
       "      <td>0.105532</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.176750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.182698</td>\n",
       "      <td>0.108104</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.212492</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.139051</td>\n",
       "      <td>0.105504</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.152460</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.181084</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.149126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.158727</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.146541</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.197656</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.154100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.223898</td>\n",
       "      <td>0.230732</td>\n",
       "      <td>0.112262</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.215303</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.107865</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.238623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.110295</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.552814</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.157992</td>\n",
       "      <td>0.263821</td>\n",
       "      <td>0.199056</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.225044</td>\n",
       "      <td>0.197164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.126761</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.194423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.100374</td>\n",
       "      <td>0.161115</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.206708</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.203814</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.148393</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.244485</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.212901</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.178156</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.188430</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.217112</td>\n",
       "      <td>0.148745</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.161948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.140664</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.217428</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.221143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.320875</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.148602</td>\n",
       "      <td>0.116165</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.128847</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.148249</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.137108</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.179836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.132658</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.123476</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.220672</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.306749</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5\n",
       "0   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000\n",
       "1   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000\n",
       "2   0.170856  0.000000  0.000000  0.000000  0.000000  0.000000\n",
       "3   0.000000  0.000000  0.000000  0.000000  0.359382  0.000000\n",
       "4   0.000000  0.103717  0.000000  0.230141  0.113409  0.000000\n",
       "5   0.266683  0.000000  0.295407  0.000000  0.000000  0.000000\n",
       "6   0.000000  0.240805  0.000000  0.000000  0.000000  0.000000\n",
       "7   0.109448  0.000000  0.000000  0.226080  0.000000  0.136623\n",
       "8   0.000000  0.000000  0.000000  0.000000  0.130642  0.000000\n",
       "9   0.000000  0.308734  0.105532  0.000000  0.000000  0.176750\n",
       "10  0.000000  0.182698  0.108104  0.000000  0.212492  0.000000\n",
       "11  0.000000  0.000000  0.000000  0.139051  0.105504  0.000000\n",
       "12  0.000000  0.152460  0.000000  0.000000  0.181084  0.000000\n",
       "13  0.000000  0.000000  0.000000  0.000000  0.000000  0.149126\n",
       "14  0.000000  0.158727  0.000000  0.000000  0.146541  0.000000\n",
       "15  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000\n",
       "16  0.000000  0.000000  0.197656  0.000000  0.000000  0.154100\n",
       "17  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000\n",
       "18  0.000000  0.223898  0.230732  0.112262  0.000000  0.000000\n",
       "19  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000\n",
       "20  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000\n",
       "21  0.215303  0.000000  0.107865  0.000000  0.000000  0.000000\n",
       "22  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000\n",
       "23  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000\n",
       "24  0.000000  0.000000  0.000000  0.000000  0.000000  0.238623\n",
       "25  0.000000  0.000000  0.110295  0.000000  0.000000  0.000000\n",
       "26  0.000000  0.000000  0.000000  0.552814  0.000000  0.000000\n",
       "27  0.157992  0.263821  0.199056  0.000000  0.225044  0.197164\n",
       "28  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000\n",
       "29  0.126761  0.000000  0.000000  0.000000  0.000000  0.194423\n",
       "30  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000\n",
       "31  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000\n",
       "32  0.100374  0.161115  0.000000  0.206708  0.000000  0.000000\n",
       "33  0.000000  0.000000  0.203814  0.000000  0.000000  0.000000\n",
       "34  0.000000  0.000000  0.000000  0.000000  0.148393  0.000000\n",
       "35  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000\n",
       "36  0.000000  0.244485  0.000000  0.000000  0.000000  0.000000\n",
       "37  0.000000  0.000000  0.212901  0.000000  0.178156  0.000000\n",
       "38  0.188430  0.000000  0.217112  0.148745  0.000000  0.161948\n",
       "39  0.000000  0.000000  0.000000  0.140664  0.000000  0.000000\n",
       "40  0.217428  0.000000  0.000000  0.000000  0.000000  0.221143\n",
       "41  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000\n",
       "42  0.320875  0.000000  0.000000  0.000000  0.000000  0.000000\n",
       "43  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000\n",
       "44  0.148602  0.116165  0.000000  0.000000  0.000000  0.000000\n",
       "45  0.128847  0.000000  0.000000  0.000000  0.148249  0.000000\n",
       "46  0.000000  0.137108  0.000000  0.000000  0.000000  0.179836\n",
       "47  0.000000  0.000000  0.132658  0.000000  0.000000  0.125819\n",
       "48  0.000000  0.000000  0.000000  0.123476  0.000000  0.000000\n",
       "49  0.220672  0.000000  0.000000  0.000000  0.306749  0.000000"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtest = np.where(cca.y_weights_ < 0.1, 0, cca.y_weights_ )\n",
    "pd.DataFrame(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "peaceful-surfing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorrect-electric",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moderate-hypothesis",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continent-vaccine",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appropriate-fruit",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lucky-craps",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
